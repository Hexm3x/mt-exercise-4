2025-05-20 17:14:16,045 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2025-05-20 17:14:16,047 - INFO - joeynmt.helpers -                           cfg.name : transformer_sample_config
2025-05-20 17:14:16,048 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2025-05-20 17:14:16,049 - INFO - joeynmt.helpers -                     cfg.data.train : nl-de/train_100k
2025-05-20 17:14:16,050 - INFO - joeynmt.helpers -                       cfg.data.dev : nl-de/dev_100k
2025-05-20 17:14:16,051 - INFO - joeynmt.helpers -                      cfg.data.test : nl-de/test_100k
2025-05-20 17:14:16,052 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2025-05-20 17:14:16,053 - INFO - joeynmt.helpers -                  cfg.data.src.lang : nl
2025-05-20 17:14:16,054 - INFO - joeynmt.helpers -                 cfg.data.src.level : word
2025-05-20 17:14:16,055 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2025-05-20 17:14:16,055 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2025-05-20 17:14:16,056 - INFO - joeynmt.helpers -             cfg.data.src.voc_limit : 2000
2025-05-20 17:14:16,057 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : space
2025-05-20 17:14:16,058 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : de
2025-05-20 17:14:16,059 - INFO - joeynmt.helpers -                 cfg.data.trg.level : word
2025-05-20 17:14:16,060 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2025-05-20 17:14:16,060 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2025-05-20 17:14:16,061 - INFO - joeynmt.helpers -             cfg.data.trg.voc_limit : 2000
2025-05-20 17:14:16,062 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : space
2025-05-20 17:14:16,063 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2025-05-20 17:14:16,064 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2025-05-20 17:14:16,065 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2025-05-20 17:14:16,066 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2025-05-20 17:14:16,067 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2025-05-20 17:14:16,068 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2025-05-20 17:14:16,069 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2025-05-20 17:14:16,070 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2025-05-20 17:14:16,071 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2025-05-20 17:14:16,072 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2025-05-20 17:14:16,073 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2025-05-20 17:14:16,074 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2025-05-20 17:14:16,075 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2025-05-20 17:14:16,077 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2025-05-20 17:14:16,081 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2025-05-20 17:14:16,082 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2025-05-20 17:14:16,083 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2025-05-20 17:14:16,084 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2025-05-20 17:14:16,086 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2025-05-20 17:14:16,087 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/word_level_new
2025-05-20 17:14:16,088 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2025-05-20 17:14:16,089 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2025-05-20 17:14:16,090 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2025-05-20 17:14:16,091 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2025-05-20 17:14:16,092 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2025-05-20 17:14:16,093 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2025-05-20 17:14:16,094 - INFO - joeynmt.helpers -            cfg.training.load_model : models/word_level/2000.ckpt
2025-05-20 17:14:16,095 - INFO - joeynmt.helpers -             cfg.training.src_vocab : models/word_level/src_vocab.txt
2025-05-20 17:14:16,096 - INFO - joeynmt.helpers -             cfg.training.trg_vocab : models/word_level/trg_vocab.txt
2025-05-20 17:14:16,096 - INFO - joeynmt.helpers -      cfg.training.save_latest_ckpt : True
2025-05-20 17:14:16,097 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2025-05-20 17:14:16,098 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2025-05-20 17:14:16,099 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2025-05-20 17:14:16,100 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2025-05-20 17:14:16,101 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2025-05-20 17:14:16,102 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : False
2025-05-20 17:14:16,103 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2025-05-20 17:14:16,104 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2025-05-20 17:14:16,105 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2025-05-20 17:14:16,106 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2025-05-20 17:14:16,106 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2025-05-20 17:14:16,107 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2025-05-20 17:14:16,108 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2025-05-20 17:14:16,109 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2025-05-20 17:14:16,110 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2025-05-20 17:14:16,111 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2025-05-20 17:14:16,112 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2025-05-20 17:14:16,113 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2025-05-20 17:14:16,113 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2025-05-20 17:14:16,114 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2025-05-20 17:14:16,115 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2025-05-20 17:14:16,116 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2025-05-20 17:14:16,117 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2025-05-20 17:14:16,117 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2025-05-20 17:14:16,118 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2025-05-20 17:14:16,322 - INFO - joeynmt.data - Building tokenizer...
2025-05-20 17:14:16,323 - INFO - joeynmt.tokenizers - nl tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none)
2025-05-20 17:14:16,324 - INFO - joeynmt.tokenizers - de tokenizer: BasicTokenizer(level=word, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none)
2025-05-20 17:14:16,324 - INFO - joeynmt.data - Loading train set...
2025-05-20 17:14:18,047 - INFO - joeynmt.data - Building vocabulary...
2025-05-20 17:14:21,000 - INFO - joeynmt.data - Loading dev set...
2025-05-20 17:14:21,103 - INFO - joeynmt.data - Loading test set...
2025-05-20 17:14:21,217 - INFO - joeynmt.data - Data loaded.
2025-05-20 17:14:21,218 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-20 17:14:21,219 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=1001, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-20 17:14:21,220 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1779, src_lang=nl, trg_lang=de, has_trg=True, random_subset=-1)
2025-05-20 17:14:21,221 - INFO - joeynmt.data - First training example:
	[SRC] Al Gore over het afwenden van de klimaatcrisis
	[TRG] Al Gore: Die Abwendung der Klimakatastrophe
2025-05-20 17:14:21,222 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) een (6) het (7) van (8) en (9) dat
2025-05-20 17:14:21,223 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) die (5) und (6) der (7) in (8) das (9) zu
2025-05-20 17:14:21,224 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 2004
2025-05-20 17:14:21,226 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 2004
2025-05-20 17:14:21,252 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-20 17:14:25,971 - INFO - joeynmt.model - Enc-dec model built.
2025-05-20 17:14:26,023 - INFO - joeynmt.model - Total params: 3925248
2025-05-20 17:14:26,025 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2025-05-20 17:14:26,026 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2025-05-20 17:14:26,028 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2025-05-20 17:14:26,029 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2025-05-20 17:14:26,030 - INFO - joeynmt.training - Loading model from models/word_level/2000.ckpt
2025-05-20 17:14:28,897 - INFO - joeynmt.helpers - Load model from /mnt/c/Users/Dieb/Desktop/mt-exercise-4/models/word_level/2000.ckpt.
2025-05-20 17:14:28,969 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2025-05-20 17:14:28,971 - INFO - joeynmt.training - EPOCH 1
2025-05-20 17:18:54,092 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     1.921387, Batch Acc: 0.425988, Tokens per Sec:      247, Lr: 0.000300
2025-05-20 17:23:13,537 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     1.963503, Batch Acc: 0.429214, Tokens per Sec:      249, Lr: 0.000300
2025-05-20 17:27:38,434 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     1.940937, Batch Acc: 0.431948, Tokens per Sec:      246, Lr: 0.000300
2025-05-20 17:32:14,510 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.021378, Batch Acc: 0.426560, Tokens per Sec:      232, Lr: 0.000300
2025-05-20 17:36:33,970 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.273830, Batch Acc: 0.433776, Tokens per Sec:      251, Lr: 0.000300
2025-05-20 17:36:33,972 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 17:36:33,973 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 17:44:08,749 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.14, ppl:   8.46, acc:   0.39, generation: 454.7611[sec], evaluation: 0.0000[sec]
2025-05-20 17:44:08,751 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-20 17:44:10,069 - INFO - joeynmt.training - Example #0
2025-05-20 17:44:10,071 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 17:44:10,072 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 17:44:10,073 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', '<unk>', '<unk>', '', '<unk>', 'die', '<unk>', '<unk>', '', '<unk>', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 17:44:10,076 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 17:44:10,078 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 17:44:10,079 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese zwei <unk> <unk> <unk> <unk>  <unk> die <unk> <unk>  <unk> die letzten drei Millionen Jahre <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 17:44:10,081 - INFO - joeynmt.training - Example #1
2025-05-20 17:44:10,086 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 17:44:10,088 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 17:44:10,089 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', 'dieser', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'des', '<unk>', '</s>']
2025-05-20 17:44:10,091 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 17:44:10,093 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 17:44:10,094 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> dieser <unk> <unk> <unk> weil es nicht die <unk> des <unk> des <unk>
2025-05-20 17:44:10,096 - INFO - joeynmt.training - Example #2
2025-05-20 17:44:10,097 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 17:44:10,098 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 17:44:10,099 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', '<unk>', '<unk>', '<unk>', '', '<unk>', '<unk>', '</s>']
2025-05-20 17:44:10,100 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 17:44:10,102 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 17:44:10,110 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist <unk> <unk> <unk>  <unk> <unk>
2025-05-20 17:44:10,112 - INFO - joeynmt.training - Example #3
2025-05-20 17:44:10,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 17:44:10,114 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 17:44:10,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-20 17:44:10,115 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 17:44:10,117 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 17:44:10,118 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in der <unk>
2025-05-20 17:44:10,119 - INFO - joeynmt.training - Example #4
2025-05-20 17:44:10,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 17:44:10,122 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 17:44:10,123 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächsten', '<unk>', 'die', 'ich', '<unk>', '<unk>', 'ist', 'ein', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 17:44:10,124 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 17:44:10,126 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 17:44:10,128 - INFO - joeynmt.training - 	Hypothesis: Die nächsten <unk> die ich <unk> <unk> ist ein <unk> <unk> <unk> <unk> <unk>
2025-05-20 17:49:07,622 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     1.890313, Batch Acc: 0.438403, Tokens per Sec:      219, Lr: 0.000300
2025-05-20 17:54:14,070 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     1.958255, Batch Acc: 0.438670, Tokens per Sec:      210, Lr: 0.000300
2025-05-20 17:58:48,881 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     1.901767, Batch Acc: 0.446669, Tokens per Sec:      245, Lr: 0.000300
2025-05-20 18:03:08,691 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     1.812407, Batch Acc: 0.444469, Tokens per Sec:      256, Lr: 0.000300
2025-05-20 18:07:26,786 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     1.869543, Batch Acc: 0.443254, Tokens per Sec:      250, Lr: 0.000300
2025-05-20 18:07:26,788 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 18:07:26,789 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 18:10:56,692 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.12, ppl:   8.29, acc:   0.39, generation: 209.8906[sec], evaluation: 0.0000[sec]
2025-05-20 18:10:56,694 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-20 18:10:57,638 - INFO - joeynmt.training - Example #0
2025-05-20 18:10:57,639 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 18:10:57,640 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 18:10:57,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 18:10:57,642 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 18:10:57,643 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 18:10:57,645 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei <unk> um zu zeigen, dass die <unk>  <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 18:10:57,646 - INFO - joeynmt.training - Example #1
2025-05-20 18:10:57,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 18:10:57,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 18:10:57,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-20 18:10:57,650 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 18:10:57,651 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 18:10:57,652 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-20 18:10:57,653 - INFO - joeynmt.training - Example #2
2025-05-20 18:10:57,654 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 18:10:57,655 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 18:10:57,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', '<unk>', '</s>']
2025-05-20 18:10:57,657 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 18:10:57,658 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 18:10:57,659 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  <unk>
2025-05-20 18:10:57,661 - INFO - joeynmt.training - Example #3
2025-05-20 18:10:57,661 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 18:10:57,662 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 18:10:57,662 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-20 18:10:57,663 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 18:10:57,664 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 18:10:57,665 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-20 18:10:57,666 - INFO - joeynmt.training - Example #4
2025-05-20 18:10:57,667 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 18:10:57,667 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 18:10:57,668 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', '', 'ist', 'eine', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 18:10:57,669 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 18:10:57,669 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 18:10:57,670 - INFO - joeynmt.training - 	Hypothesis: Der nächste <unk> die ich <unk> <unk>  ist eine <unk> <unk> <unk>
2025-05-20 18:15:13,743 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     1.863381, Batch Acc: 0.444820, Tokens per Sec:      263, Lr: 0.000300
2025-05-20 18:19:24,231 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     1.876821, Batch Acc: 0.447165, Tokens per Sec:      259, Lr: 0.000300
2025-05-20 18:23:44,626 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.065487, Batch Acc: 0.441509, Tokens per Sec:      251, Lr: 0.000300
2025-05-20 18:28:01,795 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     1.891057, Batch Acc: 0.450827, Tokens per Sec:      260, Lr: 0.000300
2025-05-20 18:32:25,955 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     1.943672, Batch Acc: 0.446722, Tokens per Sec:      241, Lr: 0.000300
2025-05-20 18:32:25,956 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 18:32:25,958 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 18:36:43,704 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.06, ppl:   7.88, acc:   0.40, generation: 257.7327[sec], evaluation: 0.0000[sec]
2025-05-20 18:36:43,720 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-20 18:37:08,807 - INFO - joeynmt.training - Example #0
2025-05-20 18:37:08,808 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 18:37:08,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 18:37:08,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'die', '<unk>', '', 'die', '<unk>', '<unk>', '<unk>', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 18:37:09,441 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 18:37:09,443 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 18:37:09,446 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> <unk> <unk> <unk> <unk> <unk> <unk> die <unk>  die <unk> <unk> <unk> die <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 18:37:09,449 - INFO - joeynmt.training - Example #1
2025-05-20 18:37:09,453 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 18:37:09,454 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 18:37:09,455 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 18:37:09,457 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 18:37:09,458 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 18:37:09,459 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 18:37:09,460 - INFO - joeynmt.training - Example #2
2025-05-20 18:37:09,461 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 18:37:09,462 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 18:37:09,462 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 18:37:09,464 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 18:37:09,466 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 18:37:09,468 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>
2025-05-20 18:37:09,469 - INFO - joeynmt.training - Example #3
2025-05-20 18:37:09,470 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 18:37:09,471 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 18:37:09,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-20 18:37:09,473 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 18:37:09,474 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 18:37:09,475 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-20 18:37:09,476 - INFO - joeynmt.training - Example #4
2025-05-20 18:37:09,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 18:37:09,478 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 18:37:09,478 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', 'die', 'ich', '<unk>', 'sehen,', '', 'ist', 'ein', '<unk>', '<unk>', '<unk>', 'was', 'die', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-20 18:37:09,479 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 18:37:09,480 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 18:37:09,482 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> die ich <unk> sehen,  ist ein <unk> <unk> <unk> was die letzten 25 Jahren <unk>
2025-05-20 18:41:44,761 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     1.874025, Batch Acc: 0.447334, Tokens per Sec:      219, Lr: 0.000300
2025-05-20 18:46:22,383 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     1.973997, Batch Acc: 0.451952, Tokens per Sec:      234, Lr: 0.000300
2025-05-20 18:51:41,756 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     1.798936, Batch Acc: 0.452400, Tokens per Sec:      210, Lr: 0.000300
2025-05-20 18:56:10,115 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     1.934142, Batch Acc: 0.455344, Tokens per Sec:      247, Lr: 0.000300
2025-05-20 19:00:32,618 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     1.986599, Batch Acc: 0.454647, Tokens per Sec:      249, Lr: 0.000300
2025-05-20 19:00:32,619 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 19:00:32,621 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 19:04:39,475 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.07, ppl:   7.91, acc:   0.40, generation: 246.8391[sec], evaluation: 0.0000[sec]
2025-05-20 19:04:40,704 - INFO - joeynmt.training - Example #0
2025-05-20 19:04:40,705 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 19:04:40,706 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 19:04:40,707 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 19:04:40,710 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 19:04:40,711 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 19:04:40,712 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese zwei <unk> <unk> um <unk> zu zeigen, dass die <unk>  die <unk>  <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 19:04:40,713 - INFO - joeynmt.training - Example #1
2025-05-20 19:04:40,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 19:04:40,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 19:04:40,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'dieses', '<unk>', 'dieses', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 19:04:40,723 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 19:04:40,725 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 19:04:40,726 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> dieses <unk> dieses <unk> <unk> <unk> weil es nicht die <unk> des <unk> <unk> <unk>
2025-05-20 19:04:40,729 - INFO - joeynmt.training - Example #2
2025-05-20 19:04:40,730 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 19:04:40,731 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 19:04:40,732 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 19:04:40,734 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 19:04:40,737 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 19:04:40,738 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  <unk> <unk> <unk>
2025-05-20 19:04:40,739 - INFO - joeynmt.training - Example #3
2025-05-20 19:04:40,741 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 19:04:40,741 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 19:04:40,742 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', 'ist', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-20 19:04:40,743 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 19:04:40,744 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 19:04:40,746 - INFO - joeynmt.training - 	Hypothesis: Es ist aus der <unk> und <unk> in der <unk>
2025-05-20 19:04:40,749 - INFO - joeynmt.training - Example #4
2025-05-20 19:04:40,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 19:04:40,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 19:04:40,756 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', 'ist', 'ein', '<unk>', '<unk>', 'Version', 'von', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'ist', '<unk>', '</s>']
2025-05-20 19:04:40,757 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 19:04:40,758 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 19:04:40,759 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk> ist ein <unk> <unk> Version von <unk> was in den letzten 25 Jahren ist <unk>
2025-05-20 19:08:57,328 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     1.927426, Batch Acc: 0.454184, Tokens per Sec:      246, Lr: 0.000300
2025-05-20 19:13:21,834 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     1.878786, Batch Acc: 0.458220, Tokens per Sec:      254, Lr: 0.000300
2025-05-20 19:17:41,660 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     1.887676, Batch Acc: 0.454948, Tokens per Sec:      255, Lr: 0.000300
2025-05-20 19:22:11,647 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     1.794266, Batch Acc: 0.455490, Tokens per Sec:      238, Lr: 0.000300
2025-05-20 19:25:32,602 - INFO - joeynmt.training - Epoch   1: total training loss 4699.86
2025-05-20 19:25:32,603 - INFO - joeynmt.training - EPOCH 2
2025-05-20 19:27:02,597 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     1.814759, Batch Acc: 0.474237, Tokens per Sec:      225, Lr: 0.000300
2025-05-20 19:27:02,599 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 19:27:02,601 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 19:32:08,139 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.53, acc:   0.41, generation: 305.5230[sec], evaluation: 0.0000[sec]
2025-05-20 19:32:08,140 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-20 19:32:09,104 - INFO - joeynmt.training - Example #0
2025-05-20 19:32:09,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 19:32:09,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 19:32:09,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', '<unk>', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'an', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', '<unk>', '<unk>', '', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 19:32:09,108 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 19:32:09,109 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 19:32:09,110 - INFO - joeynmt.training - 	Hypothesis: <unk> <unk> <unk> ich diese beiden <unk> <unk> um an <unk> zu zeigen, dass die <unk>  <unk> <unk>  <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 19:32:09,111 - INFO - joeynmt.training - Example #1
2025-05-20 19:32:09,112 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 19:32:09,113 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 19:32:09,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 19:32:09,115 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 19:32:09,116 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 19:32:09,118 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 19:32:09,119 - INFO - joeynmt.training - Example #2
2025-05-20 19:32:09,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 19:32:09,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 19:32:09,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 19:32:09,123 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 19:32:09,124 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 19:32:09,125 - INFO - joeynmt.training - 	Hypothesis: Die <unk> <unk> ist in <unk> <unk> <unk> <unk> <unk>
2025-05-20 19:32:09,127 - INFO - joeynmt.training - Example #3
2025-05-20 19:32:09,129 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 19:32:09,130 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 19:32:09,131 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-20 19:32:09,132 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 19:32:09,133 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 19:32:09,135 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in der <unk>
2025-05-20 19:32:09,136 - INFO - joeynmt.training - Example #4
2025-05-20 19:32:09,137 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 19:32:09,138 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 19:32:09,138 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', 'ist', 'eine', '<unk>', 'Version', 'von', 'der', 'letzten', '25', 'Jahren', 'ist', '<unk>', '</s>']
2025-05-20 19:32:09,140 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 19:32:09,141 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 19:32:09,142 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk> ist eine <unk> Version von der letzten 25 Jahren ist <unk>
2025-05-20 19:36:25,472 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     1.733184, Batch Acc: 0.472409, Tokens per Sec:      254, Lr: 0.000300
2025-05-20 19:40:40,073 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     1.853049, Batch Acc: 0.475338, Tokens per Sec:      264, Lr: 0.000300
2025-05-20 19:44:56,704 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.751719, Batch Acc: 0.474729, Tokens per Sec:      254, Lr: 0.000300
2025-05-20 19:49:08,388 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     1.776546, Batch Acc: 0.475480, Tokens per Sec:      258, Lr: 0.000300
2025-05-20 19:53:14,603 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     1.734338, Batch Acc: 0.469914, Tokens per Sec:      265, Lr: 0.000300
2025-05-20 19:53:14,605 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 19:53:14,606 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 19:56:24,766 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.03, ppl:   7.59, acc:   0.41, generation: 190.1470[sec], evaluation: 0.0000[sec]
2025-05-20 19:56:25,599 - INFO - joeynmt.helpers - delete models/word_level_new/2500.ckpt
2025-05-20 19:56:25,608 - INFO - joeynmt.training - Example #0
2025-05-20 19:56:25,610 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 19:56:25,610 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 19:56:25,611 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '<unk>', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 19:56:25,612 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 19:56:25,613 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 19:56:25,614 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die <unk> <unk> die letzten drei Millionen Jahre  <unk> <unk> <unk> <unk>
2025-05-20 19:56:25,615 - INFO - joeynmt.training - Example #1
2025-05-20 19:56:25,617 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 19:56:25,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 19:56:25,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', 'Problem', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-20 19:56:25,619 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 19:56:25,620 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 19:56:25,621 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> der <unk> dieses <unk> Problem Problem <unk> weil es nicht die <unk> des <unk> <unk>
2025-05-20 19:56:25,622 - INFO - joeynmt.training - Example #2
2025-05-20 19:56:25,623 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 19:56:25,624 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 19:56:25,625 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 19:56:25,626 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 19:56:25,627 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 19:56:25,628 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2025-05-20 19:56:25,630 - INFO - joeynmt.training - Example #3
2025-05-20 19:56:25,631 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 19:56:25,632 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 19:56:25,633 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-20 19:56:25,635 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 19:56:25,637 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 19:56:25,638 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-20 19:56:25,639 - INFO - joeynmt.training - Example #4
2025-05-20 19:56:25,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 19:56:25,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 19:56:25,641 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächsten', '<unk>', 'die', 'ich', 'Ihnen', 'sehen,', '', 'ist', 'ein', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-20 19:56:25,643 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 19:56:25,644 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 19:56:25,645 - INFO - joeynmt.training - 	Hypothesis: Und die nächsten <unk> die ich Ihnen sehen,  ist ein <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-20 20:00:33,419 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     1.819708, Batch Acc: 0.475493, Tokens per Sec:      267, Lr: 0.000300
2025-05-20 20:04:47,733 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     1.844005, Batch Acc: 0.470090, Tokens per Sec:      254, Lr: 0.000300
2025-05-20 20:08:55,854 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     1.704555, Batch Acc: 0.473525, Tokens per Sec:      267, Lr: 0.000300
2025-05-20 20:13:04,697 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     1.617437, Batch Acc: 0.475397, Tokens per Sec:      263, Lr: 0.000300
2025-05-20 20:17:15,462 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     1.715216, Batch Acc: 0.471427, Tokens per Sec:      259, Lr: 0.000300
2025-05-20 20:17:15,463 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 20:17:15,465 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 20:20:27,027 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.00, ppl:   7.39, acc:   0.41, generation: 191.5475[sec], evaluation: 0.0000[sec]
2025-05-20 20:20:27,029 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-20 20:20:27,927 - INFO - joeynmt.helpers - delete models/word_level_new/3000.ckpt
2025-05-20 20:20:27,936 - INFO - joeynmt.training - Example #0
2025-05-20 20:20:27,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 20:20:27,938 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 20:20:27,938 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'die', '<unk>', '', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 20:20:27,939 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 20:20:27,941 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 20:20:27,942 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> die <unk>  <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 20:20:27,943 - INFO - joeynmt.training - Example #1
2025-05-20 20:20:27,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 20:20:27,945 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 20:20:27,945 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 20:20:27,946 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 20:20:27,947 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 20:20:27,948 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 20:20:27,950 - INFO - joeynmt.training - Example #2
2025-05-20 20:20:27,951 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 20:20:27,951 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 20:20:27,952 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'die', '<unk>', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 20:20:27,953 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 20:20:27,955 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 20:20:27,956 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf die <unk> <unk> ist in <unk> <unk>  das <unk> <unk> <unk>
2025-05-20 20:20:27,957 - INFO - joeynmt.training - Example #3
2025-05-20 20:20:27,957 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 20:20:27,958 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 20:20:27,958 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-20 20:20:27,959 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 20:20:27,960 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 20:20:27,961 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in den <unk>
2025-05-20 20:20:27,962 - INFO - joeynmt.training - Example #4
2025-05-20 20:20:27,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 20:20:27,963 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 20:20:27,964 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '', 'ist', 'ein', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-20 20:20:27,965 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 20:20:27,965 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 20:20:27,966 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> die ich <unk>  ist ein <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-20 20:24:38,788 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     1.945797, Batch Acc: 0.472682, Tokens per Sec:      266, Lr: 0.000300
2025-05-20 20:28:56,041 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     1.881430, Batch Acc: 0.477662, Tokens per Sec:      260, Lr: 0.000300
2025-05-20 20:33:00,806 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     1.706950, Batch Acc: 0.472172, Tokens per Sec:      271, Lr: 0.000300
2025-05-20 20:37:22,316 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     1.834639, Batch Acc: 0.476893, Tokens per Sec:      248, Lr: 0.000300
2025-05-20 20:41:31,330 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.860703, Batch Acc: 0.470843, Tokens per Sec:      266, Lr: 0.000300
2025-05-20 20:41:31,331 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 20:41:31,332 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 20:46:41,000 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.25, acc:   0.42, generation: 309.6533[sec], evaluation: 0.0000[sec]
2025-05-20 20:46:41,002 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-20 20:46:41,927 - INFO - joeynmt.helpers - delete models/word_level_new/4000.ckpt
2025-05-20 20:46:41,940 - INFO - joeynmt.training - Example #0
2025-05-20 20:46:41,941 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 20:46:41,942 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 20:46:41,942 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 20:46:41,943 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 20:46:41,944 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 20:46:41,946 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die letzten drei Millionen Jahren <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 20:46:41,947 - INFO - joeynmt.training - Example #1
2025-05-20 20:46:41,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 20:46:41,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 20:46:41,949 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'dieses', '<unk>', '<unk>', '<unk>', '<unk>', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-20 20:46:41,950 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 20:46:41,951 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 20:46:41,952 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> dieses <unk> <unk> <unk> <unk>  denn es ist nicht die <unk> des <unk> <unk>
2025-05-20 20:46:41,953 - INFO - joeynmt.training - Example #2
2025-05-20 20:46:41,954 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 20:46:41,955 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 20:46:41,955 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 20:46:41,957 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 20:46:41,958 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 20:46:41,959 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk> <unk>
2025-05-20 20:46:41,959 - INFO - joeynmt.training - Example #3
2025-05-20 20:46:41,960 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 20:46:41,961 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 20:46:41,961 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-20 20:46:41,962 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 20:46:41,963 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 20:46:41,964 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in der <unk>
2025-05-20 20:46:41,964 - INFO - joeynmt.training - Example #4
2025-05-20 20:46:41,965 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 20:46:41,966 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 20:46:41,966 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', 'ist', 'ein', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 20:46:41,967 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 20:46:41,968 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 20:46:41,969 - INFO - joeynmt.training - 	Hypothesis: Der nächste <unk> die ich <unk> <unk> ist ein <unk> <unk> <unk> <unk> <unk>
2025-05-20 20:50:59,240 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     1.643188, Batch Acc: 0.475783, Tokens per Sec:      255, Lr: 0.000300
2025-05-20 20:55:12,306 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     1.768565, Batch Acc: 0.477658, Tokens per Sec:      259, Lr: 0.000300
2025-05-20 20:59:22,267 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     1.843374, Batch Acc: 0.478937, Tokens per Sec:      262, Lr: 0.000300
2025-05-20 21:03:35,507 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     1.776405, Batch Acc: 0.477964, Tokens per Sec:      262, Lr: 0.000300
2025-05-20 21:07:43,816 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     1.745486, Batch Acc: 0.476914, Tokens per Sec:      257, Lr: 0.000300
2025-05-20 21:07:43,818 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 21:07:43,819 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 21:11:03,384 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.06, acc:   0.42, generation: 199.5521[sec], evaluation: 0.0000[sec]
2025-05-20 21:11:03,386 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-20 21:11:04,285 - INFO - joeynmt.helpers - delete models/word_level_new/3500.ckpt
2025-05-20 21:11:04,302 - INFO - joeynmt.training - Example #0
2025-05-20 21:11:04,303 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 21:11:04,303 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 21:11:04,304 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '<unk>', '<unk>', '<unk>', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '</s>']
2025-05-20 21:11:04,305 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 21:11:04,306 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 21:11:04,307 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese zwei <unk> <unk> um zu zeigen, dass die <unk> <unk> <unk> <unk> die in den letzten drei Millionen Jahre <unk> <unk>
2025-05-20 21:11:04,308 - INFO - joeynmt.training - Example #1
2025-05-20 21:11:04,309 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 21:11:04,310 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 21:11:04,310 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', '<unk>', '<unk>', '', 'denn', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-20 21:11:04,312 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 21:11:04,312 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 21:11:04,313 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> <unk> <unk>  denn es nicht die <unk> des <unk> <unk>
2025-05-20 21:11:04,314 - INFO - joeynmt.training - Example #2
2025-05-20 21:11:04,315 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 21:11:04,316 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 21:11:04,316 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 21:11:04,317 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 21:11:04,318 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 21:11:04,319 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2025-05-20 21:11:04,319 - INFO - joeynmt.training - Example #3
2025-05-20 21:11:04,320 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 21:11:04,320 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 21:11:04,321 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-20 21:11:04,322 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 21:11:04,322 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 21:11:04,323 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in den <unk>
2025-05-20 21:11:04,324 - INFO - joeynmt.training - Example #4
2025-05-20 21:11:04,325 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 21:11:04,325 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 21:11:04,325 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'ist', '<unk>', '</s>']
2025-05-20 21:11:04,326 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 21:11:04,327 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 21:11:04,328 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> die ich <unk> <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren ist <unk>
2025-05-20 21:15:14,963 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     1.857866, Batch Acc: 0.479309, Tokens per Sec:      257, Lr: 0.000300
2025-05-20 21:19:22,889 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     1.651359, Batch Acc: 0.475768, Tokens per Sec:      263, Lr: 0.000300
2025-05-20 21:23:37,057 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     1.799024, Batch Acc: 0.477827, Tokens per Sec:      261, Lr: 0.000300
2025-05-20 21:27:46,340 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     1.655521, Batch Acc: 0.475470, Tokens per Sec:      263, Lr: 0.000300
2025-05-20 21:29:00,330 - INFO - joeynmt.training - Epoch   2: total training loss 4310.28
2025-05-20 21:29:00,331 - INFO - joeynmt.training - EPOCH 3
2025-05-20 21:31:54,032 - INFO - joeynmt.training - Epoch   3, Step:     7000, Batch Loss:     1.762170, Batch Acc: 0.492981, Tokens per Sec:      262, Lr: 0.000300
2025-05-20 21:31:54,033 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 21:31:54,034 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 21:35:15,728 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.97, acc:   0.43, generation: 201.6781[sec], evaluation: 0.0000[sec]
2025-05-20 21:35:15,730 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-20 21:35:16,653 - INFO - joeynmt.helpers - delete models/word_level_new/5000.ckpt
2025-05-20 21:35:16,667 - INFO - joeynmt.training - Example #0
2025-05-20 21:35:16,668 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 21:35:16,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 21:35:16,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '<unk>', '<unk>', 'die', '<unk>', '', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 21:35:16,670 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 21:35:16,673 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 21:35:16,675 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> um zu zeigen, dass die <unk> <unk> <unk> die <unk>  in den letzten drei Millionen Jahren <unk> <unk> <unk> <unk>
2025-05-20 21:35:16,676 - INFO - joeynmt.training - Example #1
2025-05-20 21:35:16,678 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 21:35:16,678 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 21:35:16,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 21:35:16,681 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 21:35:16,682 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 21:35:16,684 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 21:35:16,685 - INFO - joeynmt.training - Example #2
2025-05-20 21:35:16,687 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 21:35:16,687 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 21:35:16,688 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 21:35:16,689 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 21:35:16,690 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 21:35:16,691 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2025-05-20 21:35:16,692 - INFO - joeynmt.training - Example #3
2025-05-20 21:35:16,694 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 21:35:16,694 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 21:35:16,695 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-20 21:35:16,696 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 21:35:16,697 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 21:35:16,698 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-20 21:35:16,699 - INFO - joeynmt.training - Example #4
2025-05-20 21:35:16,701 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 21:35:16,702 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 21:35:16,702 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-20 21:35:16,704 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 21:35:16,706 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 21:35:16,706 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> die ich <unk> <unk> ist eine <unk> Version von dem letzten 25 Jahren <unk>
2025-05-20 21:39:31,167 - INFO - joeynmt.training - Epoch   3, Step:     7100, Batch Loss:     1.392163, Batch Acc: 0.493085, Tokens per Sec:      252, Lr: 0.000300
2025-05-20 21:43:46,638 - INFO - joeynmt.training - Epoch   3, Step:     7200, Batch Loss:     1.781863, Batch Acc: 0.494315, Tokens per Sec:      273, Lr: 0.000300
2025-05-20 21:47:51,307 - INFO - joeynmt.training - Epoch   3, Step:     7300, Batch Loss:     1.601450, Batch Acc: 0.495319, Tokens per Sec:      272, Lr: 0.000300
2025-05-20 21:51:57,633 - INFO - joeynmt.training - Epoch   3, Step:     7400, Batch Loss:     1.622227, Batch Acc: 0.495711, Tokens per Sec:      260, Lr: 0.000300
2025-05-20 21:56:08,515 - INFO - joeynmt.training - Epoch   3, Step:     7500, Batch Loss:     1.688465, Batch Acc: 0.490343, Tokens per Sec:      258, Lr: 0.000300
2025-05-20 21:56:08,517 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 21:56:08,518 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 22:00:02,231 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   7.00, acc:   0.43, generation: 233.6990[sec], evaluation: 0.0000[sec]
2025-05-20 22:00:03,101 - INFO - joeynmt.helpers - delete models/word_level_new/4500.ckpt
2025-05-20 22:00:03,169 - INFO - joeynmt.training - Example #0
2025-05-20 22:00:03,171 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 22:00:03,172 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 22:00:03,176 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'die', '<unk>', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 22:00:03,179 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 22:00:03,181 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 22:00:03,183 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um <unk> zu zeigen, dass die <unk>  die <unk> die <unk> die <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 22:00:03,184 - INFO - joeynmt.training - Example #1
2025-05-20 22:00:03,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 22:00:03,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 22:00:03,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', 'dieses', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-20 22:00:03,189 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 22:00:03,190 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 22:00:03,192 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> dieses <unk> <unk>  weil es nicht die <unk> des <unk> des <unk> <unk>
2025-05-20 22:00:03,193 - INFO - joeynmt.training - Example #2
2025-05-20 22:00:03,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 22:00:03,196 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 22:00:03,197 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 22:00:03,198 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 22:00:03,199 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 22:00:03,200 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 22:00:03,201 - INFO - joeynmt.training - Example #3
2025-05-20 22:00:03,202 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 22:00:03,203 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 22:00:03,203 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-20 22:00:03,205 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 22:00:03,206 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 22:00:03,207 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-20 22:00:03,208 - INFO - joeynmt.training - Example #4
2025-05-20 22:00:03,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 22:00:03,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 22:00:03,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-20 22:00:03,211 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 22:00:03,212 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 22:00:03,213 - INFO - joeynmt.training - 	Hypothesis: Das nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-20 22:04:11,138 - INFO - joeynmt.training - Epoch   3, Step:     7600, Batch Loss:     1.795285, Batch Acc: 0.493421, Tokens per Sec:      257, Lr: 0.000300
2025-05-20 22:08:30,829 - INFO - joeynmt.training - Epoch   3, Step:     7700, Batch Loss:     1.562183, Batch Acc: 0.494349, Tokens per Sec:      251, Lr: 0.000300
2025-05-20 22:12:42,276 - INFO - joeynmt.training - Epoch   3, Step:     7800, Batch Loss:     1.516456, Batch Acc: 0.490783, Tokens per Sec:      264, Lr: 0.000300
2025-05-20 22:16:55,981 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:     1.961404, Batch Acc: 0.487035, Tokens per Sec:      255, Lr: 0.000300
2025-05-20 22:21:07,292 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     1.521513, Batch Acc: 0.490584, Tokens per Sec:      255, Lr: 0.000300
2025-05-20 22:21:07,293 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 22:21:07,295 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 22:25:13,775 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.97, acc:   0.43, generation: 246.4666[sec], evaluation: 0.0000[sec]
2025-05-20 22:25:13,777 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-20 22:25:14,842 - INFO - joeynmt.helpers - delete models/word_level_new/5500.ckpt
2025-05-20 22:25:14,859 - INFO - joeynmt.training - Example #0
2025-05-20 22:25:14,860 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 22:25:14,861 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 22:25:14,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '<unk>', '', 'die', '<unk>', '<unk>', 'die', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 22:25:14,864 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 22:25:14,877 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 22:25:14,878 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> um <unk> zu zeigen, dass die <unk> <unk>  die <unk> <unk> die die <unk> <unk> <unk> <unk> <unk> <unk>
2025-05-20 22:25:14,879 - INFO - joeynmt.training - Example #1
2025-05-20 22:25:14,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 22:25:14,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 22:25:14,885 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-20 22:25:14,887 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 22:25:14,889 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 22:25:14,890 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk> weil es nicht die <unk> des <unk> <unk>
2025-05-20 22:25:14,892 - INFO - joeynmt.training - Example #2
2025-05-20 22:25:14,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 22:25:14,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 22:25:14,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 22:25:14,896 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 22:25:14,897 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 22:25:14,898 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> <unk> <unk>
2025-05-20 22:25:14,899 - INFO - joeynmt.training - Example #3
2025-05-20 22:25:14,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 22:25:14,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 22:25:14,903 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-20 22:25:14,904 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 22:25:14,906 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 22:25:14,907 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in der <unk>
2025-05-20 22:25:14,908 - INFO - joeynmt.training - Example #4
2025-05-20 22:25:14,910 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 22:25:14,910 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 22:25:14,911 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '', 'ist', 'ein', '<unk>', 'Version', 'von', 'dem', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-20 22:25:14,913 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 22:25:14,914 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 22:25:14,915 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk>  ist ein <unk> Version von dem <unk> was in den letzten 25 Jahren <unk>
2025-05-20 22:29:27,236 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     1.676362, Batch Acc: 0.493522, Tokens per Sec:      259, Lr: 0.000300
2025-05-20 22:33:37,911 - INFO - joeynmt.training - Epoch   3, Step:     8200, Batch Loss:     1.703837, Batch Acc: 0.494581, Tokens per Sec:      264, Lr: 0.000300
2025-05-20 22:37:49,412 - INFO - joeynmt.training - Epoch   3, Step:     8300, Batch Loss:     1.699710, Batch Acc: 0.491521, Tokens per Sec:      265, Lr: 0.000300
2025-05-20 22:42:04,258 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     1.625320, Batch Acc: 0.493105, Tokens per Sec:      257, Lr: 0.000300
2025-05-20 22:46:16,358 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     1.424554, Batch Acc: 0.493736, Tokens per Sec:      260, Lr: 0.000300
2025-05-20 22:46:16,359 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 22:46:16,361 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 22:50:10,697 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.89, acc:   0.43, generation: 234.3200[sec], evaluation: 0.0000[sec]
2025-05-20 22:50:10,699 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-20 22:50:11,590 - INFO - joeynmt.helpers - delete models/word_level_new/6000.ckpt
2025-05-20 22:50:11,608 - INFO - joeynmt.training - Example #0
2025-05-20 22:50:11,615 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 22:50:11,617 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 22:50:11,618 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '<unk>', 'die', 'in', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 22:50:11,620 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 22:50:11,621 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 22:50:11,622 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei <unk> <unk> um zu zeigen, dass die <unk>  die <unk> <unk> die in drei Millionen Jahre <unk> <unk> <unk> <unk> <unk>
2025-05-20 22:50:11,624 - INFO - joeynmt.training - Example #1
2025-05-20 22:50:11,625 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 22:50:11,626 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 22:50:11,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'der', '<unk>', 'des', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-20 22:50:11,629 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 22:50:11,630 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 22:50:11,632 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> der <unk> des <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-20 22:50:11,633 - INFO - joeynmt.training - Example #2
2025-05-20 22:50:11,634 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 22:50:11,635 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 22:50:11,636 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '</s>']
2025-05-20 22:50:11,637 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 22:50:11,639 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 22:50:11,641 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unseres <unk> <unk>
2025-05-20 22:50:11,642 - INFO - joeynmt.training - Example #3
2025-05-20 22:50:11,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 22:50:11,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 22:50:11,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-20 22:50:11,647 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 22:50:11,648 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 22:50:11,650 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-20 22:50:11,651 - INFO - joeynmt.training - Example #4
2025-05-20 22:50:11,653 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 22:50:11,653 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 22:50:11,654 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-20 22:50:11,656 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 22:50:11,657 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 22:50:11,658 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich zeigen  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-20 22:54:23,524 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     1.620261, Batch Acc: 0.488914, Tokens per Sec:      263, Lr: 0.000300
2025-05-20 22:58:41,387 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     1.591080, Batch Acc: 0.496491, Tokens per Sec:      260, Lr: 0.000300
2025-05-20 23:02:50,366 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     1.632308, Batch Acc: 0.490016, Tokens per Sec:      265, Lr: 0.000300
2025-05-20 23:07:05,151 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     1.728310, Batch Acc: 0.489660, Tokens per Sec:      257, Lr: 0.000300
2025-05-20 23:11:15,683 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     1.490471, Batch Acc: 0.488768, Tokens per Sec:      264, Lr: 0.000300
2025-05-20 23:11:15,685 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 23:11:15,686 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 23:16:23,466 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.96, ppl:   7.11, acc:   0.42, generation: 307.7660[sec], evaluation: 0.0000[sec]
2025-05-20 23:16:23,473 - INFO - joeynmt.training - Example #0
2025-05-20 23:16:23,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 23:16:23,479 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 23:16:23,479 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'habe', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '<unk>', '<unk>', 'die', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 23:16:23,481 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 23:16:23,482 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 23:16:23,484 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich habe diese zwei <unk> <unk> um zu zeigen, dass die <unk>  die <unk> <unk> <unk> die die <unk> <unk> <unk> <unk> <unk>
2025-05-20 23:16:23,486 - INFO - joeynmt.training - Example #1
2025-05-20 23:16:23,487 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 23:16:23,488 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 23:16:23,489 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'der', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-20 23:16:23,491 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 23:16:23,492 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 23:16:23,494 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> <unk>  weil es nicht der <unk> des <unk> <unk>
2025-05-20 23:16:23,496 - INFO - joeynmt.training - Example #2
2025-05-20 23:16:23,497 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 23:16:23,498 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 23:16:23,499 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 23:16:23,500 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 23:16:23,502 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 23:16:23,503 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk>  das <unk> <unk> <unk> <unk>
2025-05-20 23:16:23,504 - INFO - joeynmt.training - Example #3
2025-05-20 23:16:23,506 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 23:16:23,507 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 23:16:23,507 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-20 23:16:23,509 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 23:16:23,510 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 23:16:23,511 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-20 23:16:23,512 - INFO - joeynmt.training - Example #4
2025-05-20 23:16:23,514 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 23:16:23,514 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 23:16:23,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'vor', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-20 23:16:23,516 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 23:16:23,518 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 23:16:23,519 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version von dem, was vor den letzten 25 Jahren <unk>
2025-05-20 23:20:34,310 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     1.716087, Batch Acc: 0.486435, Tokens per Sec:      268, Lr: 0.000300
2025-05-20 23:24:46,463 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     1.544196, Batch Acc: 0.494432, Tokens per Sec:      260, Lr: 0.000300
2025-05-20 23:29:09,251 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     1.625361, Batch Acc: 0.493093, Tokens per Sec:      250, Lr: 0.000300
2025-05-20 23:32:59,402 - INFO - joeynmt.training - Epoch   3: total training loss 4109.12
2025-05-20 23:32:59,403 - INFO - joeynmt.training - EPOCH 4
2025-05-20 23:33:25,472 - INFO - joeynmt.training - Epoch   4, Step:     9400, Batch Loss:     1.629848, Batch Acc: 0.524819, Tokens per Sec:      308, Lr: 0.000300
2025-05-20 23:37:42,488 - INFO - joeynmt.training - Epoch   4, Step:     9500, Batch Loss:     1.674067, Batch Acc: 0.511172, Tokens per Sec:      259, Lr: 0.000300
2025-05-20 23:37:42,489 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-20 23:37:42,491 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-20 23:42:14,859 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.91, acc:   0.43, generation: 272.3452[sec], evaluation: 0.0000[sec]
2025-05-20 23:42:16,127 - INFO - joeynmt.helpers - delete models/word_level_new/6500.ckpt
2025-05-20 23:42:16,144 - INFO - joeynmt.training - Example #0
2025-05-20 23:42:16,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-20 23:42:16,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-20 23:42:16,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'habe', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '<unk>', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '', 'mit', '<unk>', '<unk>', '</s>']
2025-05-20 23:42:16,149 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-20 23:42:16,151 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-20 23:42:16,153 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich habe diese zwei <unk> <unk> um zu zeigen, dass die <unk>  die <unk> <unk> in den letzten drei Millionen Jahren  mit <unk> <unk>
2025-05-20 23:42:16,154 - INFO - joeynmt.training - Example #1
2025-05-20 23:42:16,156 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-20 23:42:16,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-20 23:42:16,157 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', '<unk>', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', 'zu', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2025-05-20 23:42:16,159 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-20 23:42:16,160 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-20 23:42:16,162 - INFO - joeynmt.training - 	Hypothesis: Aber dieses <unk> <unk> der <unk> dieses <unk> Problem zu <unk>  weil es nicht die <unk> des <unk>
2025-05-20 23:42:16,168 - INFO - joeynmt.training - Example #2
2025-05-20 23:42:16,170 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-20 23:42:16,171 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-20 23:42:16,171 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-20 23:42:16,173 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-20 23:42:16,174 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-20 23:42:16,176 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>
2025-05-20 23:42:16,177 - INFO - joeynmt.training - Example #3
2025-05-20 23:42:16,178 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-20 23:42:16,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-20 23:42:16,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-20 23:42:16,183 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-20 23:42:16,185 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-20 23:42:16,187 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-20 23:42:16,188 - INFO - joeynmt.training - Example #4
2025-05-20 23:42:16,189 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-20 23:42:16,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-20 23:42:16,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-20 23:42:16,192 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-20 23:42:16,194 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-20 23:42:16,194 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk> ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-20 23:46:28,525 - INFO - joeynmt.training - Epoch   4, Step:     9600, Batch Loss:     1.569449, Batch Acc: 0.514966, Tokens per Sec:      261, Lr: 0.000300
2025-05-20 23:50:32,553 - INFO - joeynmt.training - Epoch   4, Step:     9700, Batch Loss:     1.658152, Batch Acc: 0.506080, Tokens per Sec:      273, Lr: 0.000300
2025-05-20 23:54:47,657 - INFO - joeynmt.training - Epoch   4, Step:     9800, Batch Loss:     1.611274, Batch Acc: 0.505589, Tokens per Sec:      256, Lr: 0.000300
2025-05-20 23:58:57,543 - INFO - joeynmt.training - Epoch   4, Step:     9900, Batch Loss:     1.668383, Batch Acc: 0.503518, Tokens per Sec:      259, Lr: 0.000300
2025-05-21 00:03:06,746 - INFO - joeynmt.training - Epoch   4, Step:    10000, Batch Loss:     1.647164, Batch Acc: 0.503895, Tokens per Sec:      269, Lr: 0.000300
2025-05-21 00:03:06,747 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 00:03:06,748 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 00:09:03,027 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.89, acc:   0.43, generation: 356.2646[sec], evaluation: 0.0000[sec]
2025-05-21 00:09:03,871 - INFO - joeynmt.helpers - delete models/word_level_new/7500.ckpt
2025-05-21 00:09:03,885 - INFO - joeynmt.training - Example #0
2025-05-21 00:09:03,886 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 00:09:03,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 00:09:03,888 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 00:09:03,889 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 00:09:03,890 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 00:09:03,891 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die letzten drei Millionen Jahren <unk> <unk> <unk> <unk> <unk>
2025-05-21 00:09:03,892 - INFO - joeynmt.training - Example #1
2025-05-21 00:09:03,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 00:09:03,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 00:09:03,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', 'des', '<unk>', '</s>']
2025-05-21 00:09:03,895 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 00:09:03,896 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 00:09:03,897 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> <unk> <unk> <unk> <unk>  weil es nicht die <unk> des <unk> des <unk>
2025-05-21 00:09:03,899 - INFO - joeynmt.training - Example #2
2025-05-21 00:09:03,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 00:09:03,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 00:09:03,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '</s>']
2025-05-21 00:09:03,902 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 00:09:03,903 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 00:09:03,904 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> <unk>
2025-05-21 00:09:03,905 - INFO - joeynmt.training - Example #3
2025-05-21 00:09:03,906 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 00:09:03,907 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 00:09:03,908 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 00:09:03,909 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 00:09:03,910 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 00:09:03,911 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-21 00:09:03,912 - INFO - joeynmt.training - Example #4
2025-05-21 00:09:03,913 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 00:09:03,914 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 00:09:03,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'es', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 00:09:03,916 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 00:09:03,917 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 00:09:03,918 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk>  ist eine <unk> Version von dem, was es in den letzten 25 Jahren <unk>
2025-05-21 00:13:10,621 - INFO - joeynmt.training - Epoch   4, Step:    10100, Batch Loss:     1.645265, Batch Acc: 0.508590, Tokens per Sec:      265, Lr: 0.000300
2025-05-21 00:17:52,563 - INFO - joeynmt.training - Epoch   4, Step:    10200, Batch Loss:     1.444807, Batch Acc: 0.505618, Tokens per Sec:      238, Lr: 0.000300
2025-05-21 00:22:33,547 - INFO - joeynmt.training - Epoch   4, Step:    10300, Batch Loss:     1.637969, Batch Acc: 0.505683, Tokens per Sec:      235, Lr: 0.000300
2025-05-21 00:27:04,469 - INFO - joeynmt.training - Epoch   4, Step:    10400, Batch Loss:     1.570277, Batch Acc: 0.502915, Tokens per Sec:      245, Lr: 0.000300
2025-05-21 00:31:44,436 - INFO - joeynmt.training - Epoch   4, Step:    10500, Batch Loss:     1.581476, Batch Acc: 0.503191, Tokens per Sec:      237, Lr: 0.000300
2025-05-21 00:31:44,437 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 00:31:44,438 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 00:35:48,134 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.86, acc:   0.43, generation: 243.6834[sec], evaluation: 0.0000[sec]
2025-05-21 00:35:48,136 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-21 00:35:49,094 - INFO - joeynmt.helpers - delete models/word_level_new/7000.ckpt
2025-05-21 00:35:49,100 - INFO - joeynmt.training - Example #0
2025-05-21 00:35:49,102 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 00:35:49,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 00:35:49,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 00:35:49,104 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 00:35:49,105 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 00:35:49,106 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um <unk> zu zeigen, um zu zeigen, dass die <unk>  die <unk> <unk> <unk> <unk> <unk>
2025-05-21 00:35:49,106 - INFO - joeynmt.training - Example #1
2025-05-21 00:35:49,107 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 00:35:49,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 00:35:49,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'des', '<unk>', 'des', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 00:35:49,109 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 00:35:49,110 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 00:35:49,110 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> des <unk> des <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 00:35:49,111 - INFO - joeynmt.training - Example #2
2025-05-21 00:35:49,113 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 00:35:49,113 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 00:35:49,114 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Weise', '', 'das', '<unk>', '<unk>', '</s>']
2025-05-21 00:35:49,115 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 00:35:49,116 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 00:35:49,117 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Weise  das <unk> <unk>
2025-05-21 00:35:49,119 - INFO - joeynmt.training - Example #3
2025-05-21 00:35:49,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 00:35:49,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 00:35:49,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 00:35:49,122 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 00:35:49,123 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 00:35:49,123 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-21 00:35:49,124 - INFO - joeynmt.training - Example #4
2025-05-21 00:35:49,125 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 00:35:49,126 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 00:35:49,126 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 00:35:49,127 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 00:35:49,128 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 00:35:49,130 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-21 00:40:00,803 - INFO - joeynmt.training - Epoch   4, Step:    10600, Batch Loss:     1.843600, Batch Acc: 0.499508, Tokens per Sec:      249, Lr: 0.000300
2025-05-21 00:44:08,346 - INFO - joeynmt.training - Epoch   4, Step:    10700, Batch Loss:     1.695083, Batch Acc: 0.500266, Tokens per Sec:      258, Lr: 0.000300
2025-05-21 00:48:17,269 - INFO - joeynmt.training - Epoch   4, Step:    10800, Batch Loss:     1.635370, Batch Acc: 0.500577, Tokens per Sec:      261, Lr: 0.000300
2025-05-21 00:52:43,046 - INFO - joeynmt.training - Epoch   4, Step:    10900, Batch Loss:     1.616570, Batch Acc: 0.500521, Tokens per Sec:      242, Lr: 0.000300
2025-05-21 00:56:53,897 - INFO - joeynmt.training - Epoch   4, Step:    11000, Batch Loss:     1.569848, Batch Acc: 0.503592, Tokens per Sec:      265, Lr: 0.000300
2025-05-21 00:56:53,898 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 00:56:53,900 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 01:03:06,204 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.82, acc:   0.43, generation: 372.2886[sec], evaluation: 0.0000[sec]
2025-05-21 01:03:06,206 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-21 01:03:07,108 - INFO - joeynmt.helpers - delete models/word_level_new/8000.ckpt
2025-05-21 01:03:07,117 - INFO - joeynmt.training - Example #0
2025-05-21 01:03:07,118 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 01:03:07,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 01:03:07,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '<unk>', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 01:03:07,122 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 01:03:07,123 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 01:03:07,125 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um <unk> zu zeigen, dass die <unk>  die <unk> <unk> die in den letzten drei Millionen Jahren <unk> <unk> <unk>
2025-05-21 01:03:07,126 - INFO - joeynmt.training - Example #1
2025-05-21 01:03:07,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 01:03:07,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 01:03:07,129 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 01:03:07,130 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 01:03:07,131 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 01:03:07,132 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> der <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 01:03:07,133 - INFO - joeynmt.training - Example #2
2025-05-21 01:03:07,134 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 01:03:07,134 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 01:03:07,135 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'von', 'uns', '<unk>', '</s>']
2025-05-21 01:03:07,136 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 01:03:07,137 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 01:03:07,138 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> Herz von uns <unk>
2025-05-21 01:03:07,140 - INFO - joeynmt.training - Example #3
2025-05-21 01:03:07,141 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 01:03:07,141 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 01:03:07,142 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 01:03:07,143 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 01:03:07,143 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 01:03:07,144 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 01:03:07,145 - INFO - joeynmt.training - Example #4
2025-05-21 01:03:07,146 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 01:03:07,146 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 01:03:07,147 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 01:03:07,148 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 01:03:07,148 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 01:03:07,149 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem <unk> was in den letzten 25 Jahren <unk>
2025-05-21 01:07:15,809 - INFO - joeynmt.training - Epoch   4, Step:    11100, Batch Loss:     1.713155, Batch Acc: 0.500780, Tokens per Sec:      262, Lr: 0.000300
2025-05-21 01:11:24,888 - INFO - joeynmt.training - Epoch   4, Step:    11200, Batch Loss:     1.560340, Batch Acc: 0.502137, Tokens per Sec:      265, Lr: 0.000300
2025-05-21 01:15:32,485 - INFO - joeynmt.training - Epoch   4, Step:    11300, Batch Loss:     1.582340, Batch Acc: 0.509181, Tokens per Sec:      268, Lr: 0.000300
2025-05-21 01:19:37,634 - INFO - joeynmt.training - Epoch   4, Step:    11400, Batch Loss:     1.556976, Batch Acc: 0.502612, Tokens per Sec:      272, Lr: 0.000300
2025-05-21 01:23:43,226 - INFO - joeynmt.training - Epoch   4, Step:    11500, Batch Loss:     1.665719, Batch Acc: 0.502556, Tokens per Sec:      270, Lr: 0.000300
2025-05-21 01:23:43,228 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 01:23:43,229 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 01:27:46,370 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.76, acc:   0.43, generation: 243.1275[sec], evaluation: 0.0000[sec]
2025-05-21 01:27:46,372 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-21 01:27:47,248 - INFO - joeynmt.helpers - delete models/word_level_new/9500.ckpt
2025-05-21 01:27:47,260 - INFO - joeynmt.training - Example #0
2025-05-21 01:27:47,262 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 01:27:47,262 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 01:27:47,263 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '</s>']
2025-05-21 01:27:47,264 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 01:27:47,265 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 01:27:47,266 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei <unk> <unk> um <unk> zu zeigen, dass die <unk>  die in drei Millionen Jahren <unk> <unk>
2025-05-21 01:27:47,267 - INFO - joeynmt.training - Example #1
2025-05-21 01:27:47,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 01:27:47,269 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 01:27:47,269 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 01:27:47,270 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 01:27:47,272 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 01:27:47,273 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> <unk> weil es nicht die <unk> des <unk> <unk>
2025-05-21 01:27:47,274 - INFO - joeynmt.training - Example #2
2025-05-21 01:27:47,276 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 01:27:47,276 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 01:27:47,277 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 01:27:47,278 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 01:27:47,279 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 01:27:47,280 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk> <unk>
2025-05-21 01:27:47,281 - INFO - joeynmt.training - Example #3
2025-05-21 01:27:47,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 01:27:47,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 01:27:47,284 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 01:27:47,285 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 01:27:47,286 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 01:27:47,287 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in der <unk>
2025-05-21 01:27:47,288 - INFO - joeynmt.training - Example #4
2025-05-21 01:27:47,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 01:27:47,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 01:27:47,290 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 01:27:47,291 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 01:27:47,292 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 01:27:47,293 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk>  ist eine <unk> Version von dem <unk> was in den letzten 25 Jahren <unk>
2025-05-21 01:31:57,957 - INFO - joeynmt.training - Epoch   4, Step:    11600, Batch Loss:     1.522089, Batch Acc: 0.506611, Tokens per Sec:      262, Lr: 0.000300
2025-05-21 01:36:08,768 - INFO - joeynmt.training - Epoch   4, Step:    11700, Batch Loss:     1.441801, Batch Acc: 0.502039, Tokens per Sec:      262, Lr: 0.000300
2025-05-21 01:40:22,110 - INFO - joeynmt.training - Epoch   4, Step:    11800, Batch Loss:     1.592685, Batch Acc: 0.504007, Tokens per Sec:      257, Lr: 0.000300
2025-05-21 01:42:22,377 - INFO - joeynmt.training - Epoch   4: total training loss 3975.90
2025-05-21 01:42:22,379 - INFO - joeynmt.training - EPOCH 5
2025-05-21 01:44:28,244 - INFO - joeynmt.training - Epoch   5, Step:    11900, Batch Loss:     1.497813, Batch Acc: 0.527743, Tokens per Sec:      267, Lr: 0.000300
2025-05-21 01:48:36,341 - INFO - joeynmt.training - Epoch   5, Step:    12000, Batch Loss:     1.661240, Batch Acc: 0.520314, Tokens per Sec:      261, Lr: 0.000300
2025-05-21 01:48:36,343 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 01:48:36,344 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 01:54:13,827 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.90, acc:   0.43, generation: 337.4666[sec], evaluation: 0.0000[sec]
2025-05-21 01:54:13,833 - INFO - joeynmt.training - Example #0
2025-05-21 01:54:13,834 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 01:54:13,836 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 01:54:13,838 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 01:54:13,840 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 01:54:13,842 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 01:54:13,843 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um zu zeigen, um zu zeigen, dass die <unk>  die letzten drei Millionen Jahre <unk> <unk> <unk> <unk>
2025-05-21 01:54:13,845 - INFO - joeynmt.training - Example #1
2025-05-21 01:54:13,847 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 01:54:13,847 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 01:54:13,848 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', '<unk>', '<unk>', 'die', '<unk>', 'dieses', '<unk>', 'Problem', 'zu', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 01:54:13,850 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 01:54:13,851 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 01:54:13,852 - INFO - joeynmt.training - 	Hypothesis: Aber dieses <unk> <unk> die <unk> dieses <unk> Problem zu <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 01:54:13,853 - INFO - joeynmt.training - Example #2
2025-05-21 01:54:13,854 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 01:54:13,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 01:54:13,856 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 01:54:13,857 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 01:54:13,858 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 01:54:13,859 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2025-05-21 01:54:13,860 - INFO - joeynmt.training - Example #3
2025-05-21 01:54:13,861 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 01:54:13,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 01:54:13,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 01:54:13,864 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 01:54:13,865 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 01:54:13,866 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-21 01:54:13,867 - INFO - joeynmt.training - Example #4
2025-05-21 01:54:13,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 01:54:13,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 01:54:13,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'nächste', '<unk>', 'die', 'ich', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 01:54:13,871 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 01:54:13,872 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 01:54:13,872 - INFO - joeynmt.training - 	Hypothesis: Der nächste <unk> die ich <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-21 01:58:20,543 - INFO - joeynmt.training - Epoch   5, Step:    12100, Batch Loss:     1.692938, Batch Acc: 0.520712, Tokens per Sec:      258, Lr: 0.000300
2025-05-21 02:02:32,153 - INFO - joeynmt.training - Epoch   5, Step:    12200, Batch Loss:     1.528082, Batch Acc: 0.521963, Tokens per Sec:      262, Lr: 0.000300
2025-05-21 02:06:37,195 - INFO - joeynmt.training - Epoch   5, Step:    12300, Batch Loss:     1.497319, Batch Acc: 0.518841, Tokens per Sec:      275, Lr: 0.000300
2025-05-21 02:10:46,106 - INFO - joeynmt.training - Epoch   5, Step:    12400, Batch Loss:     1.646738, Batch Acc: 0.514477, Tokens per Sec:      262, Lr: 0.000300
2025-05-21 02:14:54,072 - INFO - joeynmt.training - Epoch   5, Step:    12500, Batch Loss:     1.496703, Batch Acc: 0.515488, Tokens per Sec:      271, Lr: 0.000300
2025-05-21 02:14:54,073 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 02:14:54,075 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 02:18:56,714 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.87, acc:   0.43, generation: 242.6250[sec], evaluation: 0.0000[sec]
2025-05-21 02:18:57,624 - INFO - joeynmt.helpers - delete models/word_level_new/10000.ckpt
2025-05-21 02:18:57,639 - INFO - joeynmt.training - Example #0
2025-05-21 02:18:57,640 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 02:18:57,641 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 02:18:57,642 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', 'um', 'zu', '<unk>', 'zu', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', 'die', '<unk>', 'der', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 02:18:57,643 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 02:18:57,644 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 02:18:57,644 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> um zu <unk> zu <unk>  zu zeigen, dass die <unk>  in den letzten drei Millionen Jahren <unk> <unk> die <unk> der <unk> <unk> <unk>
2025-05-21 02:18:57,645 - INFO - joeynmt.training - Example #1
2025-05-21 02:18:57,646 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 02:18:57,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 02:18:57,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 02:18:57,648 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 02:18:57,649 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 02:18:57,650 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> die <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 02:18:57,651 - INFO - joeynmt.training - Example #2
2025-05-21 02:18:57,652 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 02:18:57,653 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 02:18:57,653 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '</s>']
2025-05-21 02:18:57,654 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 02:18:57,656 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 02:18:57,657 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> Herz unseres <unk> <unk>
2025-05-21 02:18:57,658 - INFO - joeynmt.training - Example #3
2025-05-21 02:18:57,659 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 02:18:57,659 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 02:18:57,660 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 02:18:57,661 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 02:18:57,662 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 02:18:57,663 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 02:18:57,663 - INFO - joeynmt.training - Example #4
2025-05-21 02:18:57,664 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 02:18:57,665 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 02:18:57,665 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 02:18:57,666 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 02:18:57,667 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 02:18:57,668 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-21 02:23:07,408 - INFO - joeynmt.training - Epoch   5, Step:    12600, Batch Loss:     1.492788, Batch Acc: 0.519864, Tokens per Sec:      267, Lr: 0.000300
2025-05-21 02:27:14,094 - INFO - joeynmt.training - Epoch   5, Step:    12700, Batch Loss:     1.664893, Batch Acc: 0.516995, Tokens per Sec:      266, Lr: 0.000300
2025-05-21 02:31:24,689 - INFO - joeynmt.training - Epoch   5, Step:    12800, Batch Loss:     1.554600, Batch Acc: 0.516924, Tokens per Sec:      257, Lr: 0.000300
2025-05-21 02:35:31,597 - INFO - joeynmt.training - Epoch   5, Step:    12900, Batch Loss:     1.656964, Batch Acc: 0.514752, Tokens per Sec:      268, Lr: 0.000300
2025-05-21 02:39:38,128 - INFO - joeynmt.training - Epoch   5, Step:    13000, Batch Loss:     1.502321, Batch Acc: 0.518171, Tokens per Sec:      263, Lr: 0.000300
2025-05-21 02:39:38,129 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 02:39:38,130 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 02:42:47,262 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.76, acc:   0.43, generation: 189.1193[sec], evaluation: 0.0000[sec]
2025-05-21 02:42:47,264 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-21 02:42:48,153 - INFO - joeynmt.helpers - delete models/word_level_new/8500.ckpt
2025-05-21 02:42:48,160 - INFO - joeynmt.training - Example #0
2025-05-21 02:42:48,161 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 02:42:48,161 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 02:42:48,162 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', 'um', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '</s>']
2025-05-21 02:42:48,163 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 02:42:48,164 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 02:42:48,166 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> um um <unk> zu zeigen, dass die <unk>  die <unk>  die letzten drei Millionen Jahre <unk>
2025-05-21 02:42:48,167 - INFO - joeynmt.training - Example #1
2025-05-21 02:42:48,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 02:42:48,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 02:42:48,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'des', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 02:42:48,170 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 02:42:48,171 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 02:42:48,172 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> des <unk> <unk> <unk> weil es nicht die <unk> des <unk> <unk>
2025-05-21 02:42:48,173 - INFO - joeynmt.training - Example #2
2025-05-21 02:42:48,175 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 02:42:48,176 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 02:42:48,176 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 02:42:48,178 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 02:42:48,179 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 02:42:48,181 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2025-05-21 02:42:48,182 - INFO - joeynmt.training - Example #3
2025-05-21 02:42:48,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 02:42:48,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 02:42:48,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 02:42:48,187 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 02:42:48,187 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 02:42:48,188 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in der <unk>
2025-05-21 02:42:48,189 - INFO - joeynmt.training - Example #4
2025-05-21 02:42:48,190 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 02:42:48,190 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 02:42:48,191 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 02:42:48,192 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 02:42:48,193 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 02:42:48,194 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich zeigen   ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-21 02:46:56,843 - INFO - joeynmt.training - Epoch   5, Step:    13100, Batch Loss:     1.489915, Batch Acc: 0.514807, Tokens per Sec:      260, Lr: 0.000300
2025-05-21 02:51:05,278 - INFO - joeynmt.training - Epoch   5, Step:    13200, Batch Loss:     1.542814, Batch Acc: 0.515388, Tokens per Sec:      260, Lr: 0.000300
2025-05-21 02:55:13,234 - INFO - joeynmt.training - Epoch   5, Step:    13300, Batch Loss:     1.575969, Batch Acc: 0.513798, Tokens per Sec:      268, Lr: 0.000300
2025-05-21 02:59:20,985 - INFO - joeynmt.training - Epoch   5, Step:    13400, Batch Loss:     1.681353, Batch Acc: 0.507659, Tokens per Sec:      264, Lr: 0.000300
2025-05-21 03:03:25,339 - INFO - joeynmt.training - Epoch   5, Step:    13500, Batch Loss:     1.664446, Batch Acc: 0.514488, Tokens per Sec:      267, Lr: 0.000300
2025-05-21 03:03:25,340 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 03:03:25,341 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 03:08:21,977 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.79, acc:   0.43, generation: 296.6213[sec], evaluation: 0.0000[sec]
2025-05-21 03:08:22,968 - INFO - joeynmt.helpers - delete models/word_level_new/12500.ckpt
2025-05-21 03:08:22,988 - INFO - joeynmt.training - Example #0
2025-05-21 03:08:22,991 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 03:08:22,992 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 03:08:22,993 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', '<unk>', 'diese', 'zwei', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '</s>']
2025-05-21 03:08:22,995 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 03:08:22,998 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 03:08:22,999 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich <unk> diese zwei <unk> um <unk> zu zeigen, um zu zeigen, dass die <unk>  die letzten drei Millionen Jahre <unk> <unk>
2025-05-21 03:08:23,000 - INFO - joeynmt.training - Example #1
2025-05-21 03:08:23,002 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 03:08:23,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 03:08:23,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 03:08:23,005 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 03:08:23,007 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 03:08:23,008 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> der <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 03:08:23,011 - INFO - joeynmt.training - Example #2
2025-05-21 03:08:23,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 03:08:23,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 03:08:23,015 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '</s>']
2025-05-21 03:08:23,017 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 03:08:23,019 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 03:08:23,023 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk>
2025-05-21 03:08:23,025 - INFO - joeynmt.training - Example #3
2025-05-21 03:08:23,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 03:08:23,028 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 03:08:23,029 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 03:08:23,031 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 03:08:23,034 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 03:08:23,040 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 03:08:23,042 - INFO - joeynmt.training - Example #4
2025-05-21 03:08:23,043 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 03:08:23,044 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 03:08:23,045 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', 'was', 'die', 'letzten', '25', 'Jahre', '<unk>', '</s>']
2025-05-21 03:08:23,047 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 03:08:23,050 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 03:08:23,054 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk> <unk>  ist eine <unk> Version von dem <unk> was die letzten 25 Jahre <unk>
2025-05-21 03:12:51,350 - INFO - joeynmt.training - Epoch   5, Step:    13600, Batch Loss:     1.498361, Batch Acc: 0.509825, Tokens per Sec:      246, Lr: 0.000300
2025-05-21 03:18:14,406 - INFO - joeynmt.training - Epoch   5, Step:    13700, Batch Loss:     1.511244, Batch Acc: 0.510515, Tokens per Sec:      205, Lr: 0.000300
2025-05-21 03:22:26,254 - INFO - joeynmt.training - Epoch   5, Step:    13800, Batch Loss:     1.493765, Batch Acc: 0.511710, Tokens per Sec:      260, Lr: 0.000300
2025-05-21 03:26:38,339 - INFO - joeynmt.training - Epoch   5, Step:    13900, Batch Loss:     1.661784, Batch Acc: 0.513027, Tokens per Sec:      266, Lr: 0.000300
2025-05-21 03:30:52,821 - INFO - joeynmt.training - Epoch   5, Step:    14000, Batch Loss:     1.694491, Batch Acc: 0.511174, Tokens per Sec:      254, Lr: 0.000300
2025-05-21 03:30:52,822 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 03:30:52,823 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 03:35:25,224 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.74, acc:   0.43, generation: 272.3869[sec], evaluation: 0.0000[sec]
2025-05-21 03:35:25,226 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-21 03:35:26,118 - INFO - joeynmt.helpers - delete models/word_level_new/10500.ckpt
2025-05-21 03:35:26,131 - INFO - joeynmt.training - Example #0
2025-05-21 03:35:26,133 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 03:35:26,133 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 03:35:26,134 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', '', 'die', '<unk>', '<unk>', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '', 'mit', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 03:35:26,135 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 03:35:26,136 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 03:35:26,137 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um zu zeigen,  die <unk> <unk> die <unk>  die letzten drei Millionen Jahre <unk>  mit <unk> <unk> <unk>
2025-05-21 03:35:26,138 - INFO - joeynmt.training - Example #1
2025-05-21 03:35:26,140 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 03:35:26,140 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 03:35:26,141 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'die', '<unk>', 'dieses', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 03:35:26,142 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 03:35:26,144 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 03:35:26,145 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> die <unk> dieses <unk> <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 03:35:26,146 - INFO - joeynmt.training - Example #2
2025-05-21 03:35:26,147 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 03:35:26,147 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 03:35:26,148 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '</s>']
2025-05-21 03:35:26,149 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 03:35:26,150 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 03:35:26,152 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unseres <unk> <unk>
2025-05-21 03:35:26,153 - INFO - joeynmt.training - Example #3
2025-05-21 03:35:26,154 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 03:35:26,155 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 03:35:26,156 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 03:35:26,157 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 03:35:26,159 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 03:35:26,160 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in den <unk>
2025-05-21 03:35:26,161 - INFO - joeynmt.training - Example #4
2025-05-21 03:35:26,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 03:35:26,162 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 03:35:26,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahre', '<unk>', '</s>']
2025-05-21 03:35:26,164 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 03:35:26,165 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 03:35:26,165 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich <unk>  ist eine <unk> Version von dem letzten 25 Jahre <unk>
2025-05-21 03:39:31,150 - INFO - joeynmt.training - Epoch   5, Step:    14100, Batch Loss:     1.488133, Batch Acc: 0.511891, Tokens per Sec:      267, Lr: 0.000300
2025-05-21 03:43:39,754 - INFO - joeynmt.training - Epoch   5, Step:    14200, Batch Loss:     1.566335, Batch Acc: 0.510644, Tokens per Sec:      260, Lr: 0.000300
2025-05-21 03:47:54,062 - INFO - joeynmt.training - Epoch   5, Step:    14300, Batch Loss:     1.622321, Batch Acc: 0.509568, Tokens per Sec:      255, Lr: 0.000300
2025-05-21 03:48:35,539 - INFO - joeynmt.training - Epoch   5: total training loss 3880.69
2025-05-21 03:48:35,540 - INFO - joeynmt.training - EPOCH 6
2025-05-21 03:52:02,281 - INFO - joeynmt.training - Epoch   6, Step:    14400, Batch Loss:     1.442116, Batch Acc: 0.535681, Tokens per Sec:      263, Lr: 0.000300
2025-05-21 03:56:12,218 - INFO - joeynmt.training - Epoch   6, Step:    14500, Batch Loss:     1.463266, Batch Acc: 0.528996, Tokens per Sec:      261, Lr: 0.000300
2025-05-21 03:56:12,220 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 03:56:12,221 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 03:59:57,740 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.92, acc:   0.43, generation: 225.5042[sec], evaluation: 0.0000[sec]
2025-05-21 03:59:57,746 - INFO - joeynmt.training - Example #0
2025-05-21 03:59:57,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 03:59:57,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 03:59:57,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'drei', 'Millionen', 'Jahren', '<unk>', 'hatte,', '', 'mit', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 03:59:57,752 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 03:59:57,753 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 03:59:57,755 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei <unk> <unk> um <unk> zu zeigen, dass die <unk>  die in drei Millionen Jahren <unk> hatte,  mit <unk> <unk> <unk>
2025-05-21 03:59:57,757 - INFO - joeynmt.training - Example #1
2025-05-21 03:59:57,758 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 03:59:57,760 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 03:59:57,760 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', '<unk>', '<unk>', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 03:59:57,762 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 03:59:57,764 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 03:59:57,765 - INFO - joeynmt.training - 	Hypothesis: Aber dieses <unk> <unk> die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2025-05-21 03:59:57,767 - INFO - joeynmt.training - Example #2
2025-05-21 03:59:57,768 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 03:59:57,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 03:59:57,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '</s>']
2025-05-21 03:59:57,770 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 03:59:57,771 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 03:59:57,772 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unseres <unk> <unk>
2025-05-21 03:59:57,773 - INFO - joeynmt.training - Example #3
2025-05-21 03:59:57,774 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 03:59:57,775 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 03:59:57,776 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 03:59:57,778 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 03:59:57,780 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 03:59:57,781 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus der <unk> und <unk> in der <unk>
2025-05-21 03:59:57,782 - INFO - joeynmt.training - Example #4
2025-05-21 03:59:57,783 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 03:59:57,784 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 03:59:57,785 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 03:59:57,787 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 03:59:57,788 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 03:59:57,788 - INFO - joeynmt.training - 	Hypothesis: Der nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-21 04:04:11,698 - INFO - joeynmt.training - Epoch   6, Step:    14600, Batch Loss:     1.506688, Batch Acc: 0.531391, Tokens per Sec:      250, Lr: 0.000300
2025-05-21 04:08:20,827 - INFO - joeynmt.training - Epoch   6, Step:    14700, Batch Loss:     1.612058, Batch Acc: 0.529517, Tokens per Sec:      257, Lr: 0.000300
2025-05-21 04:12:34,326 - INFO - joeynmt.training - Epoch   6, Step:    14800, Batch Loss:     1.709208, Batch Acc: 0.528397, Tokens per Sec:      258, Lr: 0.000300
2025-05-21 04:16:44,991 - INFO - joeynmt.training - Epoch   6, Step:    14900, Batch Loss:     1.450223, Batch Acc: 0.526062, Tokens per Sec:      265, Lr: 0.000300
2025-05-21 04:20:54,036 - INFO - joeynmt.training - Epoch   6, Step:    15000, Batch Loss:     1.542382, Batch Acc: 0.527185, Tokens per Sec:      269, Lr: 0.000300
2025-05-21 04:20:54,038 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 04:20:54,039 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 04:25:53,019 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.69, acc:   0.43, generation: 298.9661[sec], evaluation: 0.0000[sec]
2025-05-21 04:25:53,021 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-21 04:25:53,909 - INFO - joeynmt.helpers - delete models/word_level_new/11000.ckpt
2025-05-21 04:25:53,922 - INFO - joeynmt.training - Example #0
2025-05-21 04:25:53,923 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 04:25:53,923 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 04:25:53,924 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'drei', 'Millionen', 'Jahren', '<unk>', 'hatte,', '', 'mit', 'der', 'Größe', 'des', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 04:25:53,925 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 04:25:53,926 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 04:25:53,928 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die in drei Millionen Jahren <unk> hatte,  mit der Größe des <unk> <unk> <unk>
2025-05-21 04:25:53,929 - INFO - joeynmt.training - Example #1
2025-05-21 04:25:53,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 04:25:53,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 04:25:53,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 04:25:53,932 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 04:25:53,933 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 04:25:53,934 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> die <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 04:25:53,935 - INFO - joeynmt.training - Example #2
2025-05-21 04:25:53,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 04:25:53,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 04:25:53,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '</s>']
2025-05-21 04:25:53,938 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 04:25:53,940 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 04:25:53,941 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unserer <unk>
2025-05-21 04:25:53,942 - INFO - joeynmt.training - Example #3
2025-05-21 04:25:53,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 04:25:53,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 04:25:53,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 04:25:53,945 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 04:25:53,946 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 04:25:53,946 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-21 04:25:53,947 - INFO - joeynmt.training - Example #4
2025-05-21 04:25:53,948 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 04:25:53,948 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 04:25:53,949 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', '<unk>', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 04:25:53,950 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 04:25:53,951 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 04:25:53,951 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> <unk> <unk> was in den letzten 25 Jahren <unk>
2025-05-21 04:30:09,960 - INFO - joeynmt.training - Epoch   6, Step:    15100, Batch Loss:     1.428486, Batch Acc: 0.524908, Tokens per Sec:      251, Lr: 0.000300
2025-05-21 04:34:19,694 - INFO - joeynmt.training - Epoch   6, Step:    15200, Batch Loss:     1.644609, Batch Acc: 0.524552, Tokens per Sec:      260, Lr: 0.000300
2025-05-21 04:38:27,069 - INFO - joeynmt.training - Epoch   6, Step:    15300, Batch Loss:     1.444572, Batch Acc: 0.526238, Tokens per Sec:      271, Lr: 0.000300
2025-05-21 04:42:33,058 - INFO - joeynmt.training - Epoch   6, Step:    15400, Batch Loss:     1.413548, Batch Acc: 0.523290, Tokens per Sec:      273, Lr: 0.000300
2025-05-21 04:46:40,550 - INFO - joeynmt.training - Epoch   6, Step:    15500, Batch Loss:     1.810321, Batch Acc: 0.527634, Tokens per Sec:      265, Lr: 0.000300
2025-05-21 04:46:40,552 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 04:46:40,553 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 04:50:29,066 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.87, acc:   0.43, generation: 228.4977[sec], evaluation: 0.0000[sec]
2025-05-21 04:50:29,072 - INFO - joeynmt.training - Example #0
2025-05-21 04:50:29,076 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 04:50:29,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 04:50:29,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', '', 'mit', '<unk>', '<unk>', '</s>']
2025-05-21 04:50:29,080 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 04:50:29,082 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 04:50:29,084 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> um <unk> zu zeigen, dass die <unk>  die letzten drei Millionen Jahre <unk>  mit <unk> <unk>
2025-05-21 04:50:29,087 - INFO - joeynmt.training - Example #1
2025-05-21 04:50:29,089 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 04:50:29,091 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 04:50:29,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 04:50:29,095 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 04:50:29,099 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 04:50:29,100 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2025-05-21 04:50:29,101 - INFO - joeynmt.training - Example #2
2025-05-21 04:50:29,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 04:50:29,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 04:50:29,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Weise', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 04:50:29,106 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 04:50:29,107 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 04:50:29,109 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> ist in <unk> Weise  das <unk> <unk> <unk>
2025-05-21 04:50:29,110 - INFO - joeynmt.training - Example #3
2025-05-21 04:50:29,111 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 04:50:29,112 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 04:50:29,113 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 04:50:29,114 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 04:50:29,115 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 04:50:29,116 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus <unk> und <unk> in den <unk>
2025-05-21 04:50:29,118 - INFO - joeynmt.training - Example #4
2025-05-21 04:50:29,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 04:50:29,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 04:50:29,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 04:50:29,121 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 04:50:29,122 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 04:50:29,123 - INFO - joeynmt.training - 	Hypothesis: Das nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem <unk> was in den letzten 25 Jahren <unk>
2025-05-21 04:54:43,743 - INFO - joeynmt.training - Epoch   6, Step:    15600, Batch Loss:     1.455404, Batch Acc: 0.519422, Tokens per Sec:      250, Lr: 0.000300
2025-05-21 04:58:49,672 - INFO - joeynmt.training - Epoch   6, Step:    15700, Batch Loss:     1.558160, Batch Acc: 0.521928, Tokens per Sec:      258, Lr: 0.000300
2025-05-21 05:02:54,723 - INFO - joeynmt.training - Epoch   6, Step:    15800, Batch Loss:     1.662476, Batch Acc: 0.525209, Tokens per Sec:      263, Lr: 0.000300
2025-05-21 05:07:01,535 - INFO - joeynmt.training - Epoch   6, Step:    15900, Batch Loss:     1.408229, Batch Acc: 0.523570, Tokens per Sec:      274, Lr: 0.000300
2025-05-21 05:11:18,037 - INFO - joeynmt.training - Epoch   6, Step:    16000, Batch Loss:     1.588050, Batch Acc: 0.518463, Tokens per Sec:      249, Lr: 0.000300
2025-05-21 05:11:18,040 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 05:11:18,041 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 05:17:03,117 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.85, acc:   0.43, generation: 345.0622[sec], evaluation: 0.0000[sec]
2025-05-21 05:17:03,124 - INFO - joeynmt.training - Example #0
2025-05-21 05:17:03,127 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 05:17:03,128 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 05:17:03,129 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'zwei', '<unk>', 'um', 'zu', 'sehen,', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '<unk>', 'die', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 05:17:03,131 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 05:17:03,133 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 05:17:03,135 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese zwei <unk> um zu sehen,  zu zeigen, dass die <unk>  die <unk> <unk> die die <unk> <unk> <unk> <unk> <unk>
2025-05-21 05:17:03,136 - INFO - joeynmt.training - Example #1
2025-05-21 05:17:03,138 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 05:17:03,139 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 05:17:03,140 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 05:17:03,141 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 05:17:03,144 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 05:17:03,145 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2025-05-21 05:17:03,147 - INFO - joeynmt.training - Example #2
2025-05-21 05:17:03,148 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 05:17:03,148 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 05:17:03,149 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 05:17:03,150 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 05:17:03,151 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 05:17:03,152 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk>  das <unk> <unk> <unk>
2025-05-21 05:17:03,154 - INFO - joeynmt.training - Example #3
2025-05-21 05:17:03,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 05:17:03,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 05:17:03,157 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 05:17:03,158 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 05:17:03,159 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 05:17:03,160 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 05:17:03,161 - INFO - joeynmt.training - Example #4
2025-05-21 05:17:03,162 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 05:17:03,163 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 05:17:03,163 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 05:17:03,164 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 05:17:03,165 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 05:17:03,166 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem <unk> was in den letzten 25 Jahren <unk>
2025-05-21 05:21:08,037 - INFO - joeynmt.training - Epoch   6, Step:    16100, Batch Loss:     1.469305, Batch Acc: 0.522793, Tokens per Sec:      261, Lr: 0.000300
2025-05-21 05:25:17,357 - INFO - joeynmt.training - Epoch   6, Step:    16200, Batch Loss:     1.421852, Batch Acc: 0.524911, Tokens per Sec:      265, Lr: 0.000300
2025-05-21 05:29:24,277 - INFO - joeynmt.training - Epoch   6, Step:    16300, Batch Loss:     1.579245, Batch Acc: 0.519715, Tokens per Sec:      269, Lr: 0.000300
2025-05-21 05:33:35,818 - INFO - joeynmt.training - Epoch   6, Step:    16400, Batch Loss:     1.518005, Batch Acc: 0.519294, Tokens per Sec:      258, Lr: 0.000300
2025-05-21 05:37:49,398 - INFO - joeynmt.training - Epoch   6, Step:    16500, Batch Loss:     1.526827, Batch Acc: 0.518553, Tokens per Sec:      259, Lr: 0.000300
2025-05-21 05:37:49,399 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 05:37:49,401 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 05:42:22,410 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.71, acc:   0.43, generation: 272.9940[sec], evaluation: 0.0000[sec]
2025-05-21 05:42:23,484 - INFO - joeynmt.helpers - delete models/word_level_new/13500.ckpt
2025-05-21 05:42:23,525 - INFO - joeynmt.training - Example #0
2025-05-21 05:42:23,526 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 05:42:23,527 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 05:42:23,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahre', '<unk>', 'ich', 'diese', 'beiden', '<unk>', 'um', 'zu', 'zeigen,', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'drei', 'Millionen', 'Jahre', '<unk>', '<unk>', '</s>']
2025-05-21 05:42:23,530 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 05:42:23,531 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 05:42:23,533 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahre <unk> ich diese beiden <unk> um zu zeigen, um zu zeigen, dass die <unk>  die <unk> drei Millionen Jahre <unk> <unk>
2025-05-21 05:42:23,534 - INFO - joeynmt.training - Example #1
2025-05-21 05:42:23,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 05:42:23,537 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 05:42:23,537 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'das', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2025-05-21 05:42:23,543 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 05:42:23,544 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 05:42:23,546 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> das <unk> dieses <unk> Problem  denn es ist nicht die <unk> des <unk>
2025-05-21 05:42:23,547 - INFO - joeynmt.training - Example #2
2025-05-21 05:42:23,549 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 05:42:23,549 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 05:42:23,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', 'unseres', '<unk>', '<unk>', '</s>']
2025-05-21 05:42:23,552 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 05:42:23,554 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 05:42:23,555 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk> unseres <unk> <unk>
2025-05-21 05:42:23,557 - INFO - joeynmt.training - Example #3
2025-05-21 05:42:23,559 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 05:42:23,559 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 05:42:23,560 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 05:42:23,562 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 05:42:23,563 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 05:42:23,564 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-21 05:42:23,566 - INFO - joeynmt.training - Example #4
2025-05-21 05:42:23,568 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 05:42:23,568 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 05:42:23,569 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 05:42:23,571 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 05:42:23,573 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 05:42:23,574 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem letzten 25 Jahren <unk>
2025-05-21 05:46:46,775 - INFO - joeynmt.training - Epoch   6, Step:    16600, Batch Loss:     1.465466, Batch Acc: 0.520675, Tokens per Sec:      255, Lr: 0.000300
2025-05-21 05:50:52,310 - INFO - joeynmt.training - Epoch   6, Step:    16700, Batch Loss:     1.567469, Batch Acc: 0.518667, Tokens per Sec:      267, Lr: 0.000300
2025-05-21 05:54:34,925 - INFO - joeynmt.training - Epoch   6: total training loss 3793.00
2025-05-21 05:54:34,926 - INFO - joeynmt.training - EPOCH 7
2025-05-21 05:55:04,422 - INFO - joeynmt.training - Epoch   7, Step:    16800, Batch Loss:     1.391595, Batch Acc: 0.556621, Tokens per Sec:      237, Lr: 0.000300
2025-05-21 05:59:13,155 - INFO - joeynmt.training - Epoch   7, Step:    16900, Batch Loss:     1.575182, Batch Acc: 0.541758, Tokens per Sec:      270, Lr: 0.000300
2025-05-21 06:03:27,305 - INFO - joeynmt.training - Epoch   7, Step:    17000, Batch Loss:     1.599431, Batch Acc: 0.539643, Tokens per Sec:      263, Lr: 0.000300
2025-05-21 06:03:27,306 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 06:03:27,307 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 06:07:06,143 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.70, acc:   0.43, generation: 218.8207[sec], evaluation: 0.0000[sec]
2025-05-21 06:07:07,003 - INFO - joeynmt.helpers - delete models/word_level_new/11500.ckpt
2025-05-21 06:07:07,017 - INFO - joeynmt.training - Example #0
2025-05-21 06:07:07,019 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 06:07:07,019 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 06:07:07,020 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'die', '<unk>', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', 'alt', '', 'mit', '<unk>', '</s>']
2025-05-21 06:07:07,021 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 06:07:07,022 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 06:07:07,023 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> um <unk> zu zeigen, dass die <unk>  die <unk> die <unk> die letzten drei Millionen Jahre alt  mit <unk>
2025-05-21 06:07:07,024 - INFO - joeynmt.training - Example #1
2025-05-21 06:07:07,025 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 06:07:07,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 06:07:07,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 06:07:07,028 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 06:07:07,029 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 06:07:07,029 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 06:07:07,030 - INFO - joeynmt.training - Example #2
2025-05-21 06:07:07,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 06:07:07,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 06:07:07,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 06:07:07,033 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 06:07:07,034 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 06:07:07,034 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk> <unk>
2025-05-21 06:07:07,035 - INFO - joeynmt.training - Example #3
2025-05-21 06:07:07,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 06:07:07,037 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 06:07:07,037 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 06:07:07,038 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 06:07:07,039 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 06:07:07,040 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in der <unk>
2025-05-21 06:07:07,040 - INFO - joeynmt.training - Example #4
2025-05-21 06:07:07,041 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 06:07:07,042 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 06:07:07,042 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 06:07:07,043 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 06:07:07,044 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 06:07:07,045 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem letzten 25 Jahren <unk>
2025-05-21 06:11:21,211 - INFO - joeynmt.training - Epoch   7, Step:    17100, Batch Loss:     1.540079, Batch Acc: 0.545656, Tokens per Sec:      266, Lr: 0.000300
2025-05-21 06:15:29,094 - INFO - joeynmt.training - Epoch   7, Step:    17200, Batch Loss:     1.599916, Batch Acc: 0.538913, Tokens per Sec:      262, Lr: 0.000300
2025-05-21 06:19:38,341 - INFO - joeynmt.training - Epoch   7, Step:    17300, Batch Loss:     1.452503, Batch Acc: 0.540337, Tokens per Sec:      261, Lr: 0.000300
2025-05-21 06:23:59,881 - INFO - joeynmt.training - Epoch   7, Step:    17400, Batch Loss:     1.421893, Batch Acc: 0.537177, Tokens per Sec:      251, Lr: 0.000300
2025-05-21 06:28:12,508 - INFO - joeynmt.training - Epoch   7, Step:    17500, Batch Loss:     1.434395, Batch Acc: 0.536268, Tokens per Sec:      267, Lr: 0.000300
2025-05-21 06:28:12,509 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 06:28:12,510 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 06:33:22,758 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.66, acc:   0.44, generation: 310.2337[sec], evaluation: 0.0000[sec]
2025-05-21 06:33:22,760 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-21 06:33:23,655 - INFO - joeynmt.helpers - delete models/word_level_new/13000.ckpt
2025-05-21 06:33:23,668 - INFO - joeynmt.training - Example #0
2025-05-21 06:33:23,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 06:33:23,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 06:33:23,671 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', 'hatte', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 06:33:23,672 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 06:33:23,673 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 06:33:23,674 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die <unk> die in den letzten drei Millionen Jahren <unk> hatte <unk> <unk> <unk>
2025-05-21 06:33:23,675 - INFO - joeynmt.training - Example #1
2025-05-21 06:33:23,676 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 06:33:23,677 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 06:33:23,678 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 06:33:23,679 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 06:33:23,680 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 06:33:23,681 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> die <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 06:33:23,682 - INFO - joeynmt.training - Example #2
2025-05-21 06:33:23,683 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 06:33:23,683 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 06:33:23,684 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 06:33:23,685 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 06:33:23,686 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 06:33:23,687 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2025-05-21 06:33:23,688 - INFO - joeynmt.training - Example #3
2025-05-21 06:33:23,689 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 06:33:23,690 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 06:33:23,690 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 06:33:23,691 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 06:33:23,692 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 06:33:23,693 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 06:33:23,694 - INFO - joeynmt.training - Example #4
2025-05-21 06:33:23,695 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 06:33:23,696 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 06:33:23,696 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', '<unk>', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 06:33:23,697 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 06:33:23,698 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 06:33:23,699 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> <unk> <unk> was in den letzten 25 Jahren <unk>
2025-05-21 06:37:33,757 - INFO - joeynmt.training - Epoch   7, Step:    17600, Batch Loss:     1.504765, Batch Acc: 0.537311, Tokens per Sec:      266, Lr: 0.000300
2025-05-21 06:41:46,400 - INFO - joeynmt.training - Epoch   7, Step:    17700, Batch Loss:     1.548627, Batch Acc: 0.533458, Tokens per Sec:      253, Lr: 0.000300
2025-05-21 06:45:58,281 - INFO - joeynmt.training - Epoch   7, Step:    17800, Batch Loss:     1.616970, Batch Acc: 0.534572, Tokens per Sec:      265, Lr: 0.000300
2025-05-21 06:50:05,037 - INFO - joeynmt.training - Epoch   7, Step:    17900, Batch Loss:     1.479052, Batch Acc: 0.532435, Tokens per Sec:      271, Lr: 0.000300
2025-05-21 06:54:10,248 - INFO - joeynmt.training - Epoch   7, Step:    18000, Batch Loss:     1.497561, Batch Acc: 0.527706, Tokens per Sec:      260, Lr: 0.000300
2025-05-21 06:54:10,249 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 06:54:10,251 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 06:57:46,082 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.68, acc:   0.44, generation: 215.8175[sec], evaluation: 0.0000[sec]
2025-05-21 06:57:46,948 - INFO - joeynmt.helpers - delete models/word_level_new/14000.ckpt
2025-05-21 06:57:46,962 - INFO - joeynmt.training - Example #0
2025-05-21 06:57:46,963 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 06:57:46,964 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 06:57:46,965 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'die', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '</s>']
2025-05-21 06:57:46,966 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 06:57:46,967 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 06:57:46,968 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> um <unk> zu zeigen, die <unk>  zu zeigen, dass die <unk> die in den letzten drei Millionen Jahren <unk> <unk>
2025-05-21 06:57:46,970 - INFO - joeynmt.training - Example #1
2025-05-21 06:57:46,971 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 06:57:46,971 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 06:57:46,972 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'dieses', '<unk>', '<unk>', 'das', '<unk>', '<unk>', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2025-05-21 06:57:46,973 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 06:57:46,974 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 06:57:46,976 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> dieses <unk> <unk> das <unk> <unk> <unk> weil es nicht die <unk> des <unk>
2025-05-21 06:57:46,977 - INFO - joeynmt.training - Example #2
2025-05-21 06:57:46,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 06:57:46,979 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 06:57:46,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '</s>']
2025-05-21 06:57:46,980 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 06:57:46,982 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 06:57:46,983 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> <unk>
2025-05-21 06:57:46,984 - INFO - joeynmt.training - Example #3
2025-05-21 06:57:46,985 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 06:57:46,985 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 06:57:46,986 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 06:57:46,987 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 06:57:46,988 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 06:57:46,989 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 06:57:46,989 - INFO - joeynmt.training - Example #4
2025-05-21 06:57:46,990 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 06:57:46,991 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 06:57:46,991 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 06:57:46,992 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 06:57:46,993 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 06:57:46,994 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> <unk> <unk> <unk>
2025-05-21 07:01:58,452 - INFO - joeynmt.training - Epoch   7, Step:    18100, Batch Loss:     1.481528, Batch Acc: 0.528943, Tokens per Sec:      260, Lr: 0.000300
2025-05-21 07:06:13,781 - INFO - joeynmt.training - Epoch   7, Step:    18200, Batch Loss:     1.464738, Batch Acc: 0.531484, Tokens per Sec:      258, Lr: 0.000300
2025-05-21 07:10:37,191 - INFO - joeynmt.training - Epoch   7, Step:    18300, Batch Loss:     1.400133, Batch Acc: 0.533293, Tokens per Sec:      252, Lr: 0.000300
2025-05-21 07:14:52,766 - INFO - joeynmt.training - Epoch   7, Step:    18400, Batch Loss:     1.340480, Batch Acc: 0.531048, Tokens per Sec:      266, Lr: 0.000300
2025-05-21 07:19:07,869 - INFO - joeynmt.training - Epoch   7, Step:    18500, Batch Loss:     1.560726, Batch Acc: 0.530973, Tokens per Sec:      258, Lr: 0.000300
2025-05-21 07:19:07,871 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 07:19:07,872 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 07:23:06,529 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.96, acc:   0.42, generation: 238.6425[sec], evaluation: 0.0000[sec]
2025-05-21 07:23:06,535 - INFO - joeynmt.training - Example #0
2025-05-21 07:23:06,537 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 07:23:06,538 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 07:23:06,539 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', '<unk>', 'die', 'in', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '</s>']
2025-05-21 07:23:06,542 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 07:23:06,543 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 07:23:06,545 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk> zu zeigen, dass die <unk>  die <unk> <unk> die in drei Millionen Jahren <unk> <unk>
2025-05-21 07:23:06,547 - INFO - joeynmt.training - Example #1
2025-05-21 07:23:06,549 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 07:23:06,549 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 07:23:06,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'dieses', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 07:23:06,552 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 07:23:06,554 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 07:23:06,556 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> dieses <unk> <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 07:23:06,557 - INFO - joeynmt.training - Example #2
2025-05-21 07:23:06,558 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 07:23:06,558 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 07:23:06,559 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '</s>']
2025-05-21 07:23:06,560 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 07:23:06,561 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 07:23:06,562 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unseres <unk>
2025-05-21 07:23:06,563 - INFO - joeynmt.training - Example #3
2025-05-21 07:23:06,564 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 07:23:06,565 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 07:23:06,565 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 07:23:06,567 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 07:23:06,568 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 07:23:06,569 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 07:23:06,570 - INFO - joeynmt.training - Example #4
2025-05-21 07:23:06,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 07:23:06,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 07:23:06,573 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'davon', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 07:23:06,574 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 07:23:06,575 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 07:23:06,576 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version davon was in den letzten 25 Jahren <unk>
2025-05-21 07:27:12,503 - INFO - joeynmt.training - Epoch   7, Step:    18600, Batch Loss:     1.441542, Batch Acc: 0.526411, Tokens per Sec:      271, Lr: 0.000300
2025-05-21 07:31:16,771 - INFO - joeynmt.training - Epoch   7, Step:    18700, Batch Loss:     1.514920, Batch Acc: 0.526795, Tokens per Sec:      270, Lr: 0.000300
2025-05-21 07:35:29,247 - INFO - joeynmt.training - Epoch   7, Step:    18800, Batch Loss:     1.559465, Batch Acc: 0.531509, Tokens per Sec:      254, Lr: 0.000300
2025-05-21 07:39:40,417 - INFO - joeynmt.training - Epoch   7, Step:    18900, Batch Loss:     1.657166, Batch Acc: 0.529255, Tokens per Sec:      271, Lr: 0.000300
2025-05-21 07:43:50,110 - INFO - joeynmt.training - Epoch   7, Step:    19000, Batch Loss:     1.533865, Batch Acc: 0.525844, Tokens per Sec:      260, Lr: 0.000300
2025-05-21 07:43:50,112 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 07:43:50,113 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 07:48:25,018 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.61, acc:   0.44, generation: 274.8918[sec], evaluation: 0.0000[sec]
2025-05-21 07:48:25,020 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2025-05-21 07:48:25,997 - INFO - joeynmt.helpers - delete models/word_level_new/16500.ckpt
2025-05-21 07:48:26,010 - INFO - joeynmt.training - Example #0
2025-05-21 07:48:26,012 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 07:48:26,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 07:48:26,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '<unk>', 'die', 'in', 'drei', 'Millionen', 'Jahre', '<unk>', '', 'mit', 'der', '<unk>', '<unk>', '</s>']
2025-05-21 07:48:26,016 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 07:48:26,017 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 07:48:26,019 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> um <unk> zu zeigen, um zu zeigen, dass die <unk> <unk> die in drei Millionen Jahre <unk>  mit der <unk> <unk>
2025-05-21 07:48:26,020 - INFO - joeynmt.training - Example #1
2025-05-21 07:48:26,021 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 07:48:26,022 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 07:48:26,022 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'dieses', '<unk>', '<unk>', 'das', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 07:48:26,024 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 07:48:26,025 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 07:48:26,026 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> dieses <unk> <unk> das <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 07:48:26,028 - INFO - joeynmt.training - Example #2
2025-05-21 07:48:26,029 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 07:48:26,030 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 07:48:26,030 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 07:48:26,032 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 07:48:26,033 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 07:48:26,034 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2025-05-21 07:48:26,035 - INFO - joeynmt.training - Example #3
2025-05-21 07:48:26,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 07:48:26,037 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 07:48:26,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 07:48:26,039 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 07:48:26,041 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 07:48:26,042 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-21 07:48:26,043 - INFO - joeynmt.training - Example #4
2025-05-21 07:48:26,044 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 07:48:26,044 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 07:48:26,045 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 07:48:26,046 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 07:48:26,047 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 07:48:26,049 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem <unk> was in den letzten 25 Jahren <unk>
2025-05-21 07:52:32,715 - INFO - joeynmt.training - Epoch   7, Step:    19100, Batch Loss:     1.604292, Batch Acc: 0.528092, Tokens per Sec:      265, Lr: 0.000300
2025-05-21 07:56:36,352 - INFO - joeynmt.training - Epoch   7, Step:    19200, Batch Loss:     1.493923, Batch Acc: 0.529653, Tokens per Sec:      270, Lr: 0.000300
2025-05-21 07:58:11,732 - INFO - joeynmt.training - Epoch   7: total training loss 3679.51
2025-05-21 07:58:11,733 - INFO - joeynmt.training - EPOCH 8
2025-05-21 08:00:44,080 - INFO - joeynmt.training - Epoch   8, Step:    19300, Batch Loss:     1.428625, Batch Acc: 0.557262, Tokens per Sec:      268, Lr: 0.000300
2025-05-21 08:04:51,836 - INFO - joeynmt.training - Epoch   8, Step:    19400, Batch Loss:     1.481122, Batch Acc: 0.549457, Tokens per Sec:      270, Lr: 0.000300
2025-05-21 08:09:00,820 - INFO - joeynmt.training - Epoch   8, Step:    19500, Batch Loss:     1.368961, Batch Acc: 0.552146, Tokens per Sec:      271, Lr: 0.000300
2025-05-21 08:09:00,822 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 08:09:00,823 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 08:14:06,322 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.85, acc:   0.43, generation: 305.4829[sec], evaluation: 0.0000[sec]
2025-05-21 08:14:06,328 - INFO - joeynmt.training - Example #0
2025-05-21 08:14:06,330 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 08:14:06,331 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 08:14:06,333 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 08:14:06,335 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 08:14:06,336 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 08:14:06,338 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk> zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren <unk> <unk> <unk>
2025-05-21 08:14:06,340 - INFO - joeynmt.training - Example #1
2025-05-21 08:14:06,342 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 08:14:06,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 08:14:06,343 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'der', '<unk>', 'dieses', '<unk>', 'Problem', '', 'Aber', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 08:14:06,345 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 08:14:06,347 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 08:14:06,349 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> der <unk> dieses <unk> Problem  Aber weil es nicht die <unk> des <unk> <unk>
2025-05-21 08:14:06,350 - INFO - joeynmt.training - Example #2
2025-05-21 08:14:06,351 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 08:14:06,352 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 08:14:06,352 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', 'unseres', '<unk>', '<unk>', '</s>']
2025-05-21 08:14:06,353 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 08:14:06,354 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 08:14:06,355 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk> <unk>  das <unk> <unk> unseres <unk> <unk>
2025-05-21 08:14:06,356 - INFO - joeynmt.training - Example #3
2025-05-21 08:14:06,357 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 08:14:06,357 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 08:14:06,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 08:14:06,359 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 08:14:06,360 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 08:14:06,361 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 08:14:06,362 - INFO - joeynmt.training - Example #4
2025-05-21 08:14:06,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 08:14:06,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 08:14:06,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 08:14:06,364 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 08:14:06,365 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 08:14:06,366 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-21 08:18:13,884 - INFO - joeynmt.training - Epoch   8, Step:    19600, Batch Loss:     1.526768, Batch Acc: 0.552181, Tokens per Sec:      261, Lr: 0.000300
2025-05-21 08:22:28,194 - INFO - joeynmt.training - Epoch   8, Step:    19700, Batch Loss:     1.524570, Batch Acc: 0.544269, Tokens per Sec:      259, Lr: 0.000300
2025-05-21 08:26:37,978 - INFO - joeynmt.training - Epoch   8, Step:    19800, Batch Loss:     1.523765, Batch Acc: 0.548763, Tokens per Sec:      254, Lr: 0.000300
2025-05-21 08:30:40,731 - INFO - joeynmt.training - Epoch   8, Step:    19900, Batch Loss:     1.401360, Batch Acc: 0.543084, Tokens per Sec:      271, Lr: 0.000300
2025-05-21 08:34:56,783 - INFO - joeynmt.training - Epoch   8, Step:    20000, Batch Loss:     1.435572, Batch Acc: 0.540969, Tokens per Sec:      259, Lr: 0.000300
2025-05-21 08:34:56,785 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 08:34:56,786 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 08:38:58,525 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.98, ppl:   7.27, acc:   0.42, generation: 241.7237[sec], evaluation: 0.0000[sec]
2025-05-21 08:38:58,530 - INFO - joeynmt.training - Example #0
2025-05-21 08:38:58,532 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 08:38:58,533 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 08:38:58,534 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', '', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 08:38:58,537 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 08:38:58,538 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 08:38:58,539 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk>  zu zeigen, dass die <unk>  die letzten drei Millionen Jahre  <unk> <unk> <unk>
2025-05-21 08:38:58,541 - INFO - joeynmt.training - Example #1
2025-05-21 08:38:58,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 08:38:58,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 08:38:58,544 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'des', '<unk>', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 08:38:58,546 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 08:38:58,548 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 08:38:58,550 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> des <unk> <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 08:38:58,551 - INFO - joeynmt.training - Example #2
2025-05-21 08:38:58,553 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 08:38:58,553 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 08:38:58,554 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 08:38:58,557 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 08:38:58,559 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 08:38:58,560 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk> <unk>
2025-05-21 08:38:58,561 - INFO - joeynmt.training - Example #3
2025-05-21 08:38:58,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 08:38:58,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 08:38:58,564 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 08:38:58,566 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 08:38:58,567 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 08:38:58,568 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-21 08:38:58,569 - INFO - joeynmt.training - Example #4
2025-05-21 08:38:58,570 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 08:38:58,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 08:38:58,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 08:38:58,573 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 08:38:58,574 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 08:38:58,575 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen   ist eine <unk> <unk> <unk> <unk>
2025-05-21 08:43:08,212 - INFO - joeynmt.training - Epoch   8, Step:    20100, Batch Loss:     1.444148, Batch Acc: 0.544478, Tokens per Sec:      268, Lr: 0.000300
2025-05-21 08:47:13,292 - INFO - joeynmt.training - Epoch   8, Step:    20200, Batch Loss:     1.535361, Batch Acc: 0.538787, Tokens per Sec:      264, Lr: 0.000300
2025-05-21 08:51:21,703 - INFO - joeynmt.training - Epoch   8, Step:    20300, Batch Loss:     1.383530, Batch Acc: 0.541252, Tokens per Sec:      266, Lr: 0.000300
2025-05-21 08:55:31,476 - INFO - joeynmt.training - Epoch   8, Step:    20400, Batch Loss:     1.583607, Batch Acc: 0.537377, Tokens per Sec:      268, Lr: 0.000300
2025-05-21 08:59:36,998 - INFO - joeynmt.training - Epoch   8, Step:    20500, Batch Loss:     1.446123, Batch Acc: 0.541227, Tokens per Sec:      271, Lr: 0.000300
2025-05-21 08:59:36,999 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 08:59:37,001 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 09:03:33,353 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.82, acc:   0.43, generation: 236.3391[sec], evaluation: 0.0000[sec]
2025-05-21 09:03:33,359 - INFO - joeynmt.training - Example #0
2025-05-21 09:03:33,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 09:03:33,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 09:03:33,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', '', 'die', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 09:03:33,365 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 09:03:33,367 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 09:03:33,369 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um zu zeigen, um zu zeigen, dass die <unk>   die <unk> <unk> <unk> <unk>
2025-05-21 09:03:33,371 - INFO - joeynmt.training - Example #1
2025-05-21 09:03:33,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 09:03:33,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 09:03:33,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2025-05-21 09:03:33,376 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 09:03:33,379 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 09:03:33,380 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  denn es ist nicht die <unk> des <unk>
2025-05-21 09:03:33,382 - INFO - joeynmt.training - Example #2
2025-05-21 09:03:33,383 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 09:03:33,384 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 09:03:33,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 09:03:33,387 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 09:03:33,388 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 09:03:33,390 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> <unk> <unk>  das <unk> <unk> <unk>
2025-05-21 09:03:33,391 - INFO - joeynmt.training - Example #3
2025-05-21 09:03:33,393 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 09:03:33,393 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 09:03:33,394 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 09:03:33,395 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 09:03:33,396 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 09:03:33,398 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-21 09:03:33,398 - INFO - joeynmt.training - Example #4
2025-05-21 09:03:33,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 09:03:33,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 09:03:33,401 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'von', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 09:03:33,402 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 09:03:33,403 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 09:03:33,404 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version von <unk> was in den letzten 25 Jahren <unk>
2025-05-21 09:07:41,248 - INFO - joeynmt.training - Epoch   8, Step:    20600, Batch Loss:     1.360731, Batch Acc: 0.535100, Tokens per Sec:      268, Lr: 0.000300
2025-05-21 09:11:43,980 - INFO - joeynmt.training - Epoch   8, Step:    20700, Batch Loss:     1.511508, Batch Acc: 0.536285, Tokens per Sec:      269, Lr: 0.000300
2025-05-21 09:15:53,857 - INFO - joeynmt.training - Epoch   8, Step:    20800, Batch Loss:     1.569957, Batch Acc: 0.541006, Tokens per Sec:      259, Lr: 0.000300
2025-05-21 09:20:09,759 - INFO - joeynmt.training - Epoch   8, Step:    20900, Batch Loss:     1.520783, Batch Acc: 0.535956, Tokens per Sec:      261, Lr: 0.000300
2025-05-21 09:24:24,778 - INFO - joeynmt.training - Epoch   8, Step:    21000, Batch Loss:     1.443592, Batch Acc: 0.533188, Tokens per Sec:      253, Lr: 0.000300
2025-05-21 09:24:24,780 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 09:24:24,781 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 09:29:05,288 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.73, acc:   0.43, generation: 280.4921[sec], evaluation: 0.0000[sec]
2025-05-21 09:29:05,294 - INFO - joeynmt.training - Example #0
2025-05-21 09:29:05,296 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 09:29:05,297 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 09:29:05,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '', 'ungefähr', 'die', 'Größe', 'der', 'Größe', 'der', '<unk>', '', 'mit', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 09:29:05,302 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 09:29:05,305 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 09:29:05,308 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die letzten drei Millionen Jahre  ungefähr die Größe der Größe der <unk>  mit <unk> <unk> <unk>
2025-05-21 09:29:05,309 - INFO - joeynmt.training - Example #1
2025-05-21 09:29:05,311 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 09:29:05,312 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 09:29:05,314 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'die', '<unk>', 'dieses', '<unk>', '<unk>', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 09:29:05,318 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 09:29:05,321 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 09:29:05,324 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> die <unk> dieses <unk> <unk>  denn es ist nicht die <unk> des <unk> <unk>
2025-05-21 09:29:05,326 - INFO - joeynmt.training - Example #2
2025-05-21 09:29:05,328 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 09:29:05,328 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 09:29:05,329 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 09:29:05,331 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 09:29:05,332 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 09:29:05,333 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk> <unk>
2025-05-21 09:29:05,333 - INFO - joeynmt.training - Example #3
2025-05-21 09:29:05,334 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 09:29:05,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 09:29:05,335 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 09:29:05,337 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 09:29:05,338 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 09:29:05,339 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-21 09:29:05,340 - INFO - joeynmt.training - Example #4
2025-05-21 09:29:05,341 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 09:29:05,342 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 09:29:05,342 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 09:29:05,343 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 09:29:05,345 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 09:29:05,346 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-21 09:33:17,993 - INFO - joeynmt.training - Epoch   8, Step:    21100, Batch Loss:     1.356885, Batch Acc: 0.535928, Tokens per Sec:      261, Lr: 0.000300
2025-05-21 09:37:29,391 - INFO - joeynmt.training - Epoch   8, Step:    21200, Batch Loss:     1.565735, Batch Acc: 0.538044, Tokens per Sec:      255, Lr: 0.000300
2025-05-21 09:41:42,056 - INFO - joeynmt.training - Epoch   8, Step:    21300, Batch Loss:     1.545857, Batch Acc: 0.535550, Tokens per Sec:      260, Lr: 0.000300
2025-05-21 09:45:49,245 - INFO - joeynmt.training - Epoch   8, Step:    21400, Batch Loss:     1.440095, Batch Acc: 0.544955, Tokens per Sec:      268, Lr: 0.000300
2025-05-21 09:49:59,082 - INFO - joeynmt.training - Epoch   8, Step:    21500, Batch Loss:     1.445772, Batch Acc: 0.534289, Tokens per Sec:      272, Lr: 0.000300
2025-05-21 09:49:59,083 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 09:49:59,085 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 09:54:16,248 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.90, ppl:   6.67, acc:   0.43, generation: 257.1488[sec], evaluation: 0.0000[sec]
2025-05-21 09:54:17,141 - INFO - joeynmt.helpers - delete models/word_level_new/17000.ckpt
2025-05-21 09:54:17,154 - INFO - joeynmt.training - Example #0
2025-05-21 09:54:17,155 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 09:54:17,156 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 09:54:17,157 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', '<unk>', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', '', 'ungefähr', 'die', 'Größe', 'des', '<unk>', '<unk>', 'mit', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 09:54:17,158 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 09:54:17,159 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 09:54:17,160 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr <unk> ich diese beiden <unk> <unk> um <unk> zu zeigen, dass die <unk>  die <unk> in den letzten drei Millionen Jahre  ungefähr die Größe des <unk> <unk> mit <unk> <unk> <unk>
2025-05-21 09:54:17,162 - INFO - joeynmt.training - Example #1
2025-05-21 09:54:17,163 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 09:54:17,164 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 09:54:17,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 09:54:17,167 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 09:54:17,168 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 09:54:17,169 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 09:54:17,171 - INFO - joeynmt.training - Example #2
2025-05-21 09:54:17,173 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 09:54:17,173 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 09:54:17,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '</s>']
2025-05-21 09:54:17,176 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 09:54:17,177 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 09:54:17,178 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unseres <unk>
2025-05-21 09:54:17,179 - INFO - joeynmt.training - Example #3
2025-05-21 09:54:17,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 09:54:17,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 09:54:17,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'der', '<unk>', '</s>']
2025-05-21 09:54:17,183 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 09:54:17,184 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 09:54:17,185 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in der <unk>
2025-05-21 09:54:17,186 - INFO - joeynmt.training - Example #4
2025-05-21 09:54:17,187 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 09:54:17,187 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 09:54:17,187 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'nächste', '<unk>', 'den', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 09:54:17,188 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 09:54:17,189 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 09:54:17,190 - INFO - joeynmt.training - 	Hypothesis: Und der nächste <unk> den ich Ihnen <unk>  ist eine <unk> Version von dem letzten 25 Jahren <unk>
2025-05-21 09:58:23,413 - INFO - joeynmt.training - Epoch   8, Step:    21600, Batch Loss:     1.563383, Batch Acc: 0.535181, Tokens per Sec:      263, Lr: 0.000300
2025-05-21 10:02:18,062 - INFO - joeynmt.training - Epoch   8: total training loss 3615.54
2025-05-21 10:02:18,063 - INFO - joeynmt.training - EPOCH 9
2025-05-21 10:02:35,513 - INFO - joeynmt.training - Epoch   9, Step:    21700, Batch Loss:     1.493767, Batch Acc: 0.542728, Tokens per Sec:      266, Lr: 0.000300
2025-05-21 10:06:41,029 - INFO - joeynmt.training - Epoch   9, Step:    21800, Batch Loss:     1.355377, Batch Acc: 0.562641, Tokens per Sec:      272, Lr: 0.000300
2025-05-21 10:10:46,886 - INFO - joeynmt.training - Epoch   9, Step:    21900, Batch Loss:     1.499982, Batch Acc: 0.557132, Tokens per Sec:      265, Lr: 0.000300
2025-05-21 10:14:54,732 - INFO - joeynmt.training - Epoch   9, Step:    22000, Batch Loss:     1.410790, Batch Acc: 0.555283, Tokens per Sec:      267, Lr: 0.000300
2025-05-21 10:14:54,734 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 10:14:54,735 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 10:19:25,157 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.83, acc:   0.43, generation: 270.4069[sec], evaluation: 0.0000[sec]
2025-05-21 10:19:25,163 - INFO - joeynmt.training - Example #0
2025-05-21 10:19:25,165 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 10:19:25,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 10:19:25,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahren', 'habe', 'ich', 'diese', 'beiden', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '<unk>', 'hatte,', '', 'mit', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 10:19:25,171 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 10:19:25,172 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 10:19:25,174 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahren habe ich diese beiden <unk> um <unk> zu zeigen, um <unk> zu zeigen, dass die <unk> die letzten drei Millionen Jahre <unk> hatte,  mit <unk> <unk> <unk>
2025-05-21 10:19:25,176 - INFO - joeynmt.training - Example #1
2025-05-21 10:19:25,177 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 10:19:25,178 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 10:19:25,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2025-05-21 10:19:25,181 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 10:19:25,183 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 10:19:25,186 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> die <unk> dieses <unk> Problem <unk> denn es ist nicht die <unk> des <unk>
2025-05-21 10:19:25,187 - INFO - joeynmt.training - Example #2
2025-05-21 10:19:25,188 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 10:19:25,189 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 10:19:25,190 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '</s>']
2025-05-21 10:19:25,191 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 10:19:25,193 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 10:19:25,194 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk>
2025-05-21 10:19:25,195 - INFO - joeynmt.training - Example #3
2025-05-21 10:19:25,198 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 10:19:25,199 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 10:19:25,199 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 10:19:25,203 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 10:19:25,204 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 10:19:25,206 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 10:19:25,207 - INFO - joeynmt.training - Example #4
2025-05-21 10:19:25,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 10:19:25,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 10:19:25,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'davon,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 10:19:25,211 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 10:19:25,212 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 10:19:25,213 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version davon, was in den letzten 25 Jahren <unk>
2025-05-21 10:23:28,475 - INFO - joeynmt.training - Epoch   9, Step:    22100, Batch Loss:     1.354284, Batch Acc: 0.556290, Tokens per Sec:      261, Lr: 0.000300
2025-05-21 10:27:39,272 - INFO - joeynmt.training - Epoch   9, Step:    22200, Batch Loss:     1.390189, Batch Acc: 0.551959, Tokens per Sec:      262, Lr: 0.000300
2025-05-21 10:31:45,806 - INFO - joeynmt.training - Epoch   9, Step:    22300, Batch Loss:     1.429087, Batch Acc: 0.554966, Tokens per Sec:      268, Lr: 0.000300
2025-05-21 10:35:52,888 - INFO - joeynmt.training - Epoch   9, Step:    22400, Batch Loss:     1.359163, Batch Acc: 0.554068, Tokens per Sec:      269, Lr: 0.000300
2025-05-21 10:40:02,218 - INFO - joeynmt.training - Epoch   9, Step:    22500, Batch Loss:     1.456395, Batch Acc: 0.548728, Tokens per Sec:      266, Lr: 0.000300
2025-05-21 10:40:02,219 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 10:40:02,221 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 10:44:26,760 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.87, acc:   0.43, generation: 264.5263[sec], evaluation: 0.0000[sec]
2025-05-21 10:44:26,766 - INFO - joeynmt.training - Example #0
2025-05-21 10:44:26,768 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 10:44:26,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 10:44:26,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', 'die', '<unk>', '<unk>', '</s>']
2025-05-21 10:44:26,773 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 10:44:26,774 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 10:44:26,776 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren <unk> <unk> die <unk> <unk>
2025-05-21 10:44:26,778 - INFO - joeynmt.training - Example #1
2025-05-21 10:44:26,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 10:44:26,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 10:44:26,782 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', '<unk>', 'dieses', '<unk>', 'Problem', 'der', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 10:44:26,784 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 10:44:26,786 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 10:44:26,788 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> <unk> dieses <unk> Problem der <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 10:44:26,789 - INFO - joeynmt.training - Example #2
2025-05-21 10:44:26,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 10:44:26,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 10:44:26,792 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', 'unserer', '<unk>', '</s>']
2025-05-21 10:44:26,793 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 10:44:26,794 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 10:44:26,795 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk> unserer <unk>
2025-05-21 10:44:26,796 - INFO - joeynmt.training - Example #3
2025-05-21 10:44:26,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 10:44:26,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 10:44:26,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 10:44:26,800 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 10:44:26,802 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 10:44:26,803 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 10:44:26,804 - INFO - joeynmt.training - Example #4
2025-05-21 10:44:26,805 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 10:44:26,805 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 10:44:26,806 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'davon', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 10:44:26,807 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 10:44:26,808 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 10:44:26,809 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version davon was in den letzten 25 Jahren <unk>
2025-05-21 10:48:37,290 - INFO - joeynmt.training - Epoch   9, Step:    22600, Batch Loss:     1.424875, Batch Acc: 0.550175, Tokens per Sec:      261, Lr: 0.000300
2025-05-21 10:52:45,383 - INFO - joeynmt.training - Epoch   9, Step:    22700, Batch Loss:     1.442932, Batch Acc: 0.549165, Tokens per Sec:      269, Lr: 0.000300
2025-05-21 10:56:59,753 - INFO - joeynmt.training - Epoch   9, Step:    22800, Batch Loss:     1.319537, Batch Acc: 0.549669, Tokens per Sec:      257, Lr: 0.000300
2025-05-21 11:01:08,942 - INFO - joeynmt.training - Epoch   9, Step:    22900, Batch Loss:     1.423471, Batch Acc: 0.547077, Tokens per Sec:      265, Lr: 0.000300
2025-05-21 11:05:18,836 - INFO - joeynmt.training - Epoch   9, Step:    23000, Batch Loss:     1.410316, Batch Acc: 0.542833, Tokens per Sec:      263, Lr: 0.000300
2025-05-21 11:05:18,838 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 11:05:18,839 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 11:09:24,611 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.89, acc:   0.43, generation: 245.7585[sec], evaluation: 0.0000[sec]
2025-05-21 11:09:24,618 - INFO - joeynmt.training - Example #0
2025-05-21 11:09:24,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 11:09:24,622 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 11:09:24,623 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'letzten', 'drei', 'Millionen', 'Jahre', '', 'in', 'etwa', 'die', '<unk>', 'Jahre', '<unk>', '<unk>', '</s>']
2025-05-21 11:09:24,626 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 11:09:24,628 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 11:09:24,630 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk> zu zeigen, dass die <unk>  die letzten drei Millionen Jahre  in etwa die <unk> Jahre <unk> <unk>
2025-05-21 11:09:24,632 - INFO - joeynmt.training - Example #1
2025-05-21 11:09:24,633 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 11:09:24,634 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 11:09:24,635 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2025-05-21 11:09:24,637 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 11:09:24,639 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 11:09:24,640 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk>
2025-05-21 11:09:24,641 - INFO - joeynmt.training - Example #2
2025-05-21 11:09:24,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 11:09:24,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 11:09:24,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 11:09:24,645 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 11:09:24,647 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 11:09:24,648 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> ist in <unk> <unk> <unk> <unk>
2025-05-21 11:09:24,649 - INFO - joeynmt.training - Example #3
2025-05-21 11:09:24,651 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 11:09:24,651 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 11:09:24,652 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 11:09:24,653 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 11:09:24,654 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 11:09:24,655 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in den <unk>
2025-05-21 11:09:24,656 - INFO - joeynmt.training - Example #4
2025-05-21 11:09:24,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 11:09:24,658 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 11:09:24,659 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'davon', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 11:09:24,660 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 11:09:24,661 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 11:09:24,662 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version davon was in den letzten 25 Jahren <unk>
2025-05-21 11:13:33,286 - INFO - joeynmt.training - Epoch   9, Step:    23100, Batch Loss:     1.590466, Batch Acc: 0.545927, Tokens per Sec:      272, Lr: 0.000300
2025-05-21 11:17:37,012 - INFO - joeynmt.training - Epoch   9, Step:    23200, Batch Loss:     1.427378, Batch Acc: 0.545695, Tokens per Sec:      267, Lr: 0.000300
2025-05-21 11:21:48,853 - INFO - joeynmt.training - Epoch   9, Step:    23300, Batch Loss:     1.538943, Batch Acc: 0.539137, Tokens per Sec:      260, Lr: 0.000300
2025-05-21 11:25:55,432 - INFO - joeynmt.training - Epoch   9, Step:    23400, Batch Loss:     1.499062, Batch Acc: 0.546975, Tokens per Sec:      267, Lr: 0.000300
2025-05-21 11:30:04,940 - INFO - joeynmt.training - Epoch   9, Step:    23500, Batch Loss:     1.438522, Batch Acc: 0.546435, Tokens per Sec:      263, Lr: 0.000300
2025-05-21 11:30:04,941 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 11:30:04,942 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 11:34:57,738 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.74, acc:   0.44, generation: 292.7821[sec], evaluation: 0.0000[sec]
2025-05-21 11:34:57,744 - INFO - joeynmt.training - Example #0
2025-05-21 11:34:57,746 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 11:34:57,746 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 11:34:57,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 11:34:57,749 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 11:34:57,751 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 11:34:57,752 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> <unk> um <unk> zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren <unk> <unk> <unk>
2025-05-21 11:34:57,754 - INFO - joeynmt.training - Example #1
2025-05-21 11:34:57,756 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 11:34:57,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 11:34:57,758 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'dieses', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 11:34:57,760 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 11:34:57,761 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 11:34:57,763 - INFO - joeynmt.training - 	Hypothesis: Aber dieses <unk> tatsächlich die <unk> dieses <unk> Problem <unk> denn es ist nicht die <unk> des <unk> <unk>
2025-05-21 11:34:57,764 - INFO - joeynmt.training - Example #2
2025-05-21 11:34:57,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 11:34:57,767 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 11:34:57,768 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', 'Weise', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '</s>']
2025-05-21 11:34:57,770 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 11:34:57,772 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 11:34:57,774 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> Weise <unk>  das <unk> Herz unseres <unk>
2025-05-21 11:34:57,775 - INFO - joeynmt.training - Example #3
2025-05-21 11:34:57,777 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 11:34:57,777 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 11:34:57,778 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 11:34:57,780 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 11:34:57,781 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 11:34:57,782 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 11:34:57,783 - INFO - joeynmt.training - Example #4
2025-05-21 11:34:57,784 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 11:34:57,785 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 11:34:57,786 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '<unk>', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem,', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 11:34:57,787 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 11:34:57,788 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 11:34:57,789 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen <unk>  ist eine <unk> Version von dem, was in den letzten 25 Jahren <unk>
2025-05-21 11:39:09,578 - INFO - joeynmt.training - Epoch   9, Step:    23600, Batch Loss:     1.458073, Batch Acc: 0.546458, Tokens per Sec:      260, Lr: 0.000210
2025-05-21 11:43:21,792 - INFO - joeynmt.training - Epoch   9, Step:    23700, Batch Loss:     1.438757, Batch Acc: 0.548005, Tokens per Sec:      264, Lr: 0.000210
2025-05-21 11:47:32,653 - INFO - joeynmt.training - Epoch   9, Step:    23800, Batch Loss:     1.486184, Batch Acc: 0.550482, Tokens per Sec:      255, Lr: 0.000210
2025-05-21 11:51:38,835 - INFO - joeynmt.training - Epoch   9, Step:    23900, Batch Loss:     1.465294, Batch Acc: 0.551806, Tokens per Sec:      272, Lr: 0.000210
2025-05-21 11:55:47,621 - INFO - joeynmt.training - Epoch   9, Step:    24000, Batch Loss:     1.468707, Batch Acc: 0.552702, Tokens per Sec:      271, Lr: 0.000210
2025-05-21 11:55:47,623 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 11:55:47,624 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 11:59:58,729 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.80, acc:   0.43, generation: 251.0906[sec], evaluation: 0.0000[sec]
2025-05-21 11:59:58,735 - INFO - joeynmt.training - Example #0
2025-05-21 11:59:58,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 11:59:58,738 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 11:59:58,740 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'um', '<unk>', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', '<unk>', '</s>']
2025-05-21 11:59:58,742 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 11:59:58,743 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 11:59:58,745 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> um <unk> zu zeigen, um <unk> dass die <unk>  die in den letzten drei Millionen Jahren <unk> <unk>
2025-05-21 11:59:58,746 - INFO - joeynmt.training - Example #1
2025-05-21 11:59:58,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 11:59:58,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 11:59:58,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'ist', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 11:59:58,751 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 11:59:58,753 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 11:59:58,755 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> ist die <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 11:59:58,756 - INFO - joeynmt.training - Example #2
2025-05-21 11:59:58,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 11:59:58,758 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 11:59:58,758 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '<unk>', '</s>']
2025-05-21 11:59:58,759 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 11:59:58,761 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 11:59:58,762 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unseres <unk> <unk>
2025-05-21 11:59:58,763 - INFO - joeynmt.training - Example #3
2025-05-21 11:59:58,764 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 11:59:58,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 11:59:58,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 11:59:58,767 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 11:59:58,768 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 11:59:58,770 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 11:59:58,771 - INFO - joeynmt.training - Example #4
2025-05-21 11:59:58,772 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 11:59:58,772 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 11:59:58,773 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 11:59:58,774 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 11:59:58,775 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 11:59:58,776 - INFO - joeynmt.training - 	Hypothesis: Und der nächste <unk> die ich Ihnen  ist eine <unk> Version von dem <unk> was in den letzten 25 Jahren <unk>
2025-05-21 12:04:19,158 - INFO - joeynmt.training - Epoch   9, Step:    24100, Batch Loss:     1.351781, Batch Acc: 0.553636, Tokens per Sec:      255, Lr: 0.000210
2025-05-21 12:06:35,990 - INFO - joeynmt.training - Epoch   9: total training loss 3528.05
2025-05-21 12:06:35,992 - INFO - joeynmt.training - EPOCH 10
2025-05-21 12:09:43,327 - INFO - joeynmt.training - Epoch  10, Step:    24200, Batch Loss:     1.266259, Batch Acc: 0.583124, Tokens per Sec:      185, Lr: 0.000210
2025-05-21 12:13:53,837 - INFO - joeynmt.training - Epoch  10, Step:    24300, Batch Loss:     1.339162, Batch Acc: 0.577603, Tokens per Sec:      259, Lr: 0.000210
2025-05-21 12:18:12,939 - INFO - joeynmt.training - Epoch  10, Step:    24400, Batch Loss:     1.342913, Batch Acc: 0.577833, Tokens per Sec:      254, Lr: 0.000210
2025-05-21 12:22:42,486 - INFO - joeynmt.training - Epoch  10, Step:    24500, Batch Loss:     1.443246, Batch Acc: 0.575346, Tokens per Sec:      244, Lr: 0.000210
2025-05-21 12:22:42,487 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 12:22:42,489 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 12:27:35,934 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.81, acc:   0.44, generation: 293.4187[sec], evaluation: 0.0000[sec]
2025-05-21 12:27:35,941 - INFO - joeynmt.training - Example #0
2025-05-21 12:27:35,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 12:27:35,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 12:27:35,947 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '<unk>', 'hatte,', '', 'mit', '<unk>', '<unk>', '</s>']
2025-05-21 12:27:35,949 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 12:27:35,950 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 12:27:35,951 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> um <unk> zu zeigen, um zu zeigen, dass die <unk> die in den letzten drei Millionen Jahren <unk> hatte,  mit <unk> <unk>
2025-05-21 12:27:35,952 - INFO - joeynmt.training - Example #1
2025-05-21 12:27:35,954 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 12:27:35,955 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 12:27:35,955 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', 'der', '<unk>', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 12:27:35,958 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 12:27:35,959 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 12:27:35,960 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem der <unk> weil es nicht die <unk> des <unk> <unk>
2025-05-21 12:27:35,962 - INFO - joeynmt.training - Example #2
2025-05-21 12:27:35,966 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 12:27:35,967 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 12:27:35,968 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unserer', '<unk>', '</s>']
2025-05-21 12:27:35,970 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 12:27:35,972 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 12:27:35,973 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unserer <unk>
2025-05-21 12:27:35,974 - INFO - joeynmt.training - Example #3
2025-05-21 12:27:35,976 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 12:27:35,977 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 12:27:35,978 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 12:27:35,980 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 12:27:35,982 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 12:27:35,985 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 12:27:35,986 - INFO - joeynmt.training - Example #4
2025-05-21 12:27:35,988 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 12:27:35,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 12:27:35,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 12:27:35,991 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 12:27:35,993 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 12:27:35,994 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen   ist eine <unk> Version von dem letzten 25 Jahren <unk>
2025-05-21 12:32:08,739 - INFO - joeynmt.training - Epoch  10, Step:    24600, Batch Loss:     1.287570, Batch Acc: 0.578478, Tokens per Sec:      238, Lr: 0.000210
2025-05-21 12:36:21,797 - INFO - joeynmt.training - Epoch  10, Step:    24700, Batch Loss:     1.352405, Batch Acc: 0.576511, Tokens per Sec:      258, Lr: 0.000210
2025-05-21 12:40:29,647 - INFO - joeynmt.training - Epoch  10, Step:    24800, Batch Loss:     1.310818, Batch Acc: 0.572141, Tokens per Sec:      265, Lr: 0.000210
2025-05-21 12:44:41,129 - INFO - joeynmt.training - Epoch  10, Step:    24900, Batch Loss:     1.351086, Batch Acc: 0.573780, Tokens per Sec:      253, Lr: 0.000210
2025-05-21 12:48:52,739 - INFO - joeynmt.training - Epoch  10, Step:    25000, Batch Loss:     1.349990, Batch Acc: 0.570482, Tokens per Sec:      268, Lr: 0.000210
2025-05-21 12:48:52,741 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 12:48:52,742 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 12:52:46,887 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.90, acc:   0.43, generation: 234.1312[sec], evaluation: 0.0000[sec]
2025-05-21 12:52:46,894 - INFO - joeynmt.training - Example #0
2025-05-21 12:52:46,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 12:52:46,898 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 12:52:46,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '', 'mit', '<unk>', '<unk>', '<unk>', 'war.', '</s>']
2025-05-21 12:52:46,900 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 12:52:46,902 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 12:52:46,905 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> um <unk> zu zeigen, um zu zeigen, dass die <unk>  die <unk> in den letzten drei Millionen Jahren  mit <unk> <unk> <unk> war.
2025-05-21 12:52:46,907 - INFO - joeynmt.training - Example #1
2025-05-21 12:52:46,909 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 12:52:46,910 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 12:52:46,914 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 12:52:46,916 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 12:52:46,918 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 12:52:46,919 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem <unk>  weil es nicht die <unk> des <unk> <unk>
2025-05-21 12:52:46,920 - INFO - joeynmt.training - Example #2
2025-05-21 12:52:46,922 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 12:52:46,922 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 12:52:46,923 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 12:52:46,924 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 12:52:46,926 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 12:52:46,927 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> ist in <unk> <unk> <unk>
2025-05-21 12:52:46,929 - INFO - joeynmt.training - Example #3
2025-05-21 12:52:46,931 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 12:52:46,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 12:52:46,933 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 12:52:46,935 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 12:52:46,936 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 12:52:46,937 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 12:52:46,938 - INFO - joeynmt.training - Example #4
2025-05-21 12:52:46,939 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 12:52:46,940 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 12:52:46,941 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 12:52:46,942 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 12:52:46,943 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 12:52:46,944 - INFO - joeynmt.training - 	Hypothesis: Die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem letzten 25 Jahren <unk>
2025-05-21 12:56:56,364 - INFO - joeynmt.training - Epoch  10, Step:    25100, Batch Loss:     1.372431, Batch Acc: 0.566001, Tokens per Sec:      264, Lr: 0.000210
2025-05-21 13:01:02,418 - INFO - joeynmt.training - Epoch  10, Step:    25200, Batch Loss:     1.319312, Batch Acc: 0.574063, Tokens per Sec:      264, Lr: 0.000210
2025-05-21 13:05:12,866 - INFO - joeynmt.training - Epoch  10, Step:    25300, Batch Loss:     1.387998, Batch Acc: 0.569037, Tokens per Sec:      267, Lr: 0.000210
2025-05-21 13:09:26,255 - INFO - joeynmt.training - Epoch  10, Step:    25400, Batch Loss:     1.387424, Batch Acc: 0.565225, Tokens per Sec:      255, Lr: 0.000210
2025-05-21 13:13:38,593 - INFO - joeynmt.training - Epoch  10, Step:    25500, Batch Loss:     1.464529, Batch Acc: 0.567510, Tokens per Sec:      262, Lr: 0.000210
2025-05-21 13:13:38,594 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 13:13:38,595 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 13:18:07,325 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.95, ppl:   6.99, acc:   0.43, generation: 268.7153[sec], evaluation: 0.0000[sec]
2025-05-21 13:18:07,332 - INFO - joeynmt.training - Example #0
2025-05-21 13:18:07,334 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 13:18:07,335 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 13:18:07,336 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', 'um', '<unk>', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', '<unk>', 'die', 'in', 'drei', 'Millionen', 'Jahren', '<unk>', 'Jahre', '', 'mit', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 13:18:07,338 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 13:18:07,340 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 13:18:07,341 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> um <unk> zu zeigen, dass die <unk>  die <unk> die in drei Millionen Jahren <unk> Jahre  mit <unk> <unk> <unk>
2025-05-21 13:18:07,343 - INFO - joeynmt.training - Example #1
2025-05-21 13:18:07,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 13:18:07,346 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 13:18:07,347 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '', 'weil', 'es', 'nicht', 'die', '<unk>', 'des', '<unk>', '<unk>', '</s>']
2025-05-21 13:18:07,348 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 13:18:07,350 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 13:18:07,352 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem  weil es nicht die <unk> des <unk> <unk>
2025-05-21 13:18:07,353 - INFO - joeynmt.training - Example #2
2025-05-21 13:18:07,355 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 13:18:07,355 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 13:18:07,356 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', '<unk>', '<unk>', '<unk>', '</s>']
2025-05-21 13:18:07,358 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 13:18:07,359 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 13:18:07,361 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> ist in <unk> <unk>  das <unk> <unk> <unk> <unk>
2025-05-21 13:18:07,363 - INFO - joeynmt.training - Example #3
2025-05-21 13:18:07,364 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 13:18:07,365 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 13:18:07,366 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'aus', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 13:18:07,367 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 13:18:07,369 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 13:18:07,370 - INFO - joeynmt.training - 	Hypothesis: Es <unk> aus <unk> und <unk> in den <unk>
2025-05-21 13:18:07,371 - INFO - joeynmt.training - Example #4
2025-05-21 13:18:07,372 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 13:18:07,373 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 13:18:07,374 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Das', 'nächste', '<unk>', 'den', 'ich', 'Ihnen', 'zeigen', '', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 13:18:07,375 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 13:18:07,376 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 13:18:07,377 - INFO - joeynmt.training - 	Hypothesis: Das nächste <unk> den ich Ihnen zeigen   ist eine <unk> Version von dem letzten 25 Jahren <unk>
2025-05-21 13:22:14,460 - INFO - joeynmt.training - Epoch  10, Step:    25600, Batch Loss:     1.345758, Batch Acc: 0.566784, Tokens per Sec:      263, Lr: 0.000210
2025-05-21 13:26:22,491 - INFO - joeynmt.training - Epoch  10, Step:    25700, Batch Loss:     1.385268, Batch Acc: 0.566948, Tokens per Sec:      273, Lr: 0.000210
2025-05-21 13:30:31,205 - INFO - joeynmt.training - Epoch  10, Step:    25800, Batch Loss:     1.435070, Batch Acc: 0.564399, Tokens per Sec:      272, Lr: 0.000210
2025-05-21 13:57:45,142 - INFO - joeynmt.training - Epoch  10, Step:    25900, Batch Loss:     1.485989, Batch Acc: 0.566377, Tokens per Sec:       41, Lr: 0.000210
2025-05-21 14:02:23,668 - INFO - joeynmt.training - Epoch  10, Step:    26000, Batch Loss:     1.421234, Batch Acc: 0.565756, Tokens per Sec:      239, Lr: 0.000210
2025-05-21 14:02:23,669 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 14:02:23,671 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 14:07:43,572 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.93, ppl:   6.89, acc:   0.43, generation: 319.8846[sec], evaluation: 0.0000[sec]
2025-05-21 14:07:43,580 - INFO - joeynmt.training - Example #0
2025-05-21 14:07:43,582 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 14:07:43,583 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 14:07:43,584 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'beiden', '<unk>', 'um', 'zu', 'zeigen,', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahren', '', 'mit', '<unk>', '<unk>', '</s>']
2025-05-21 14:07:43,586 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 14:07:43,588 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 14:07:43,591 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese beiden <unk> um zu zeigen, um zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahren  mit <unk> <unk>
2025-05-21 14:07:43,593 - INFO - joeynmt.training - Example #1
2025-05-21 14:07:43,595 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 14:07:43,596 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 14:07:43,599 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2025-05-21 14:07:43,601 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 14:07:43,603 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 14:07:43,605 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem <unk>  denn es ist nicht die <unk> des <unk>
2025-05-21 14:07:43,606 - INFO - joeynmt.training - Example #2
2025-05-21 14:07:43,608 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 14:07:43,609 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 14:07:43,609 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Der', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', 'das', '<unk>', 'Herz', 'unseres', '<unk>', '</s>']
2025-05-21 14:07:43,611 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 14:07:43,613 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 14:07:43,615 - INFO - joeynmt.training - 	Hypothesis: Der <unk> auf der <unk> ist in <unk> <unk>  das <unk> Herz unseres <unk>
2025-05-21 14:07:43,617 - INFO - joeynmt.training - Example #3
2025-05-21 14:07:43,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 14:07:43,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 14:07:43,621 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'den', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 14:07:43,623 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 14:07:43,625 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 14:07:43,627 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in den <unk> und <unk> in den <unk>
2025-05-21 14:07:43,628 - INFO - joeynmt.training - Example #4
2025-05-21 14:07:43,630 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 14:07:43,631 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 14:07:43,631 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'der', 'nächste', '<unk>', 'den', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 14:07:43,633 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 14:07:43,634 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 14:07:43,635 - INFO - joeynmt.training - 	Hypothesis: Und der nächste <unk> den ich Ihnen zeigen  ist eine <unk> Version von dem letzten 25 Jahren <unk>
2025-05-21 14:12:45,219 - INFO - joeynmt.training - Epoch  10, Step:    26100, Batch Loss:     1.391307, Batch Acc: 0.567529, Tokens per Sec:      219, Lr: 0.000210
2025-05-21 14:18:17,011 - INFO - joeynmt.training - Epoch  10, Step:    26200, Batch Loss:     1.515453, Batch Acc: 0.564251, Tokens per Sec:      201, Lr: 0.000210
2025-05-21 14:23:13,694 - INFO - joeynmt.training - Epoch  10, Step:    26300, Batch Loss:     1.550500, Batch Acc: 0.568185, Tokens per Sec:      217, Lr: 0.000210
2025-05-21 14:27:41,628 - INFO - joeynmt.training - Epoch  10, Step:    26400, Batch Loss:     1.318203, Batch Acc: 0.563824, Tokens per Sec:      244, Lr: 0.000210
2025-05-21 14:32:52,301 - INFO - joeynmt.training - Epoch  10, Step:    26500, Batch Loss:     1.463762, Batch Acc: 0.565399, Tokens per Sec:      208, Lr: 0.000210
2025-05-21 14:32:52,303 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 14:32:52,304 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 14:38:52,705 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.82, acc:   0.44, generation: 360.3868[sec], evaluation: 0.0000[sec]
2025-05-21 14:38:52,711 - INFO - joeynmt.training - Example #0
2025-05-21 14:38:52,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['Vorig', 'jaar', 'liet', 'ik', 'deze', 'twee', "dia's", 'zien', 'om', 'aan', '', 'te', 'tonen', 'dat', 'de', 'poolijskap,', '', 'die', 'de', 'afgelopen', 'drie', 'miljoen', 'jaar', '', 'ongeveer', 'de', 'grootte', 'had', 'van', 'het', 'vasteland', 'van', 'de', 'VS,', '', 'met', '40%', 'gekrompen', 'was.']
2025-05-21 14:38:52,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Letztes', 'Jahr', 'habe', 'ich', 'diese', 'beiden', 'Folien', 'gezeigt,', 'um', 'zu', 'veranschaulichen,', 'dass', 'die', 'arktische', 'Eiskappe,', 'die', 'für', 'annähernd', 'drei', 'Millionen', 'Jahre', 'die', 'Grösse', 'der', 'unteren', '48', 'Staaten', 'hatte,', 'um', '40', 'Prozent', 'geschrumpft', 'ist.']
2025-05-21 14:38:52,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['<unk>', 'Jahr', 'habe', 'ich', 'diese', 'zwei', '<unk>', '<unk>', 'um', 'zu', 'zeigen,', 'um', 'zu', 'zeigen,', 'dass', 'die', '<unk>', '', 'die', 'in', 'den', 'letzten', 'drei', 'Millionen', 'Jahre', '', 'mit', '<unk>', '<unk>', '</s>']
2025-05-21 14:38:52,718 - INFO - joeynmt.training - 	Source:     Vorig jaar liet ik deze twee dia's zien om aan  te tonen dat de poolijskap,  die de afgelopen drie miljoen jaar  ongeveer de grootte had van het vasteland van de VS,  met 40% gekrompen was.
2025-05-21 14:38:52,720 - INFO - joeynmt.training - 	Reference:  Letztes Jahr habe ich diese beiden Folien gezeigt, um zu veranschaulichen, dass die arktische Eiskappe, die für annähernd drei Millionen Jahre die Grösse der unteren 48 Staaten hatte, um 40 Prozent geschrumpft ist.
2025-05-21 14:38:52,721 - INFO - joeynmt.training - 	Hypothesis: <unk> Jahr habe ich diese zwei <unk> <unk> um zu zeigen, um zu zeigen, dass die <unk>  die in den letzten drei Millionen Jahre  mit <unk> <unk>
2025-05-21 14:38:52,722 - INFO - joeynmt.training - Example #1
2025-05-21 14:38:52,723 - DEBUG - joeynmt.training - 	Tokenized source:     ['Maar', 'dit', 'onderschat', 'eigenlijk', 'de', 'ernst', 'van', 'dit', 'specifieke', 'probleem', '', 'omdat', 'het', 'niet', 'de', 'dikte', 'van', 'het', 'ijs', 'laat', 'zien.']
2025-05-21 14:38:52,724 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Aber', 'dies', 'drückt', 'nicht', 'stark', 'genug', 'die', 'Ernsthaftigkeit', 'dieses', 'speziellen', 'Problems', 'aus,', 'da', 'es', 'nicht', 'die', 'Dicke', 'des', 'Eises', 'zeigt.']
2025-05-21 14:38:52,724 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Aber', 'das', '<unk>', 'tatsächlich', 'die', '<unk>', 'dieses', '<unk>', 'Problem', '<unk>', '', 'denn', 'es', 'ist', 'nicht', 'die', '<unk>', 'des', '<unk>', '</s>']
2025-05-21 14:38:52,725 - INFO - joeynmt.training - 	Source:     Maar dit onderschat eigenlijk de ernst van dit specifieke probleem  omdat het niet de dikte van het ijs laat zien.
2025-05-21 14:38:52,726 - INFO - joeynmt.training - 	Reference:  Aber dies drückt nicht stark genug die Ernsthaftigkeit dieses speziellen Problems aus, da es nicht die Dicke des Eises zeigt.
2025-05-21 14:38:52,728 - INFO - joeynmt.training - 	Hypothesis: Aber das <unk> tatsächlich die <unk> dieses <unk> Problem <unk>  denn es ist nicht die <unk> des <unk>
2025-05-21 14:38:52,729 - INFO - joeynmt.training - Example #2
2025-05-21 14:38:52,730 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'ijskap', 'op', 'de', 'Noordpool', 'is', 'in', 'zekere', 'zin', '', 'het', 'kloppend', 'hart', 'van', 'ons', 'globaal', 'klimaatsysteem.']
2025-05-21 14:38:52,730 - DEBUG - joeynmt.training - 	Tokenized reference:  ['In', 'gewissem', 'Sinne', 'ist', 'die', 'arktische', 'Eiskappe', 'das', 'schlagende', 'Herz', 'unseres', 'globalen', 'Klimasystems.']
2025-05-21 14:38:52,731 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Die', '<unk>', 'auf', 'der', '<unk>', 'ist', 'in', '<unk>', '<unk>', '', '<unk>', 'von', 'unserem', '<unk>', '<unk>', '</s>']
2025-05-21 14:38:52,732 - INFO - joeynmt.training - 	Source:     De ijskap op de Noordpool is in zekere zin  het kloppend hart van ons globaal klimaatsysteem.
2025-05-21 14:38:52,733 - INFO - joeynmt.training - 	Reference:  In gewissem Sinne ist die arktische Eiskappe das schlagende Herz unseres globalen Klimasystems.
2025-05-21 14:38:52,735 - INFO - joeynmt.training - 	Hypothesis: Die <unk> auf der <unk> ist in <unk> <unk>  <unk> von unserem <unk> <unk>
2025-05-21 14:38:52,736 - INFO - joeynmt.training - Example #3
2025-05-21 14:38:52,737 - DEBUG - joeynmt.training - 	Tokenized source:     ['Het', 'zet', 'uit', 'in', 'de', 'winter', 'en', 'krimpt', 'in', 'de', 'zomer.']
2025-05-21 14:38:52,737 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Sie', 'wächst', 'im', 'Winter', 'und', 'schrumpft', 'im', 'Sommer.']
2025-05-21 14:38:52,738 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Es', '<unk>', 'in', 'der', '<unk>', 'und', '<unk>', 'in', 'den', '<unk>', '</s>']
2025-05-21 14:38:52,739 - INFO - joeynmt.training - 	Source:     Het zet uit in de winter en krimpt in de zomer.
2025-05-21 14:38:52,740 - INFO - joeynmt.training - 	Reference:  Sie wächst im Winter und schrumpft im Sommer.
2025-05-21 14:38:52,741 - INFO - joeynmt.training - 	Hypothesis: Es <unk> in der <unk> und <unk> in den <unk>
2025-05-21 14:38:52,743 - INFO - joeynmt.training - Example #4
2025-05-21 14:38:52,744 - DEBUG - joeynmt.training - 	Tokenized source:     ['De', 'volgende', 'dia', 'die', 'ik', 'laat', 'zien', '', 'is', 'een', 'versnelde', 'versie', 'van', 'wat', 'er', 'de', 'afgelopen', '25', 'jaar', 'is', 'gebeurd.']
2025-05-21 14:38:52,744 - DEBUG - joeynmt.training - 	Tokenized reference:  ['Die', 'nächste', 'Folie,', 'die', 'ich', 'Ihnen', 'zeige,', 'ist', 'eine', 'Zeitrafferaufnahme', 'was', 'in', 'den', 'letzten', '25', 'Jahren', 'passiert', 'ist.']
2025-05-21 14:38:52,745 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Und', 'die', 'nächste', '<unk>', 'die', 'ich', 'Ihnen', 'zeigen', '', 'ist', 'eine', '<unk>', 'Version', 'von', 'dem', '<unk>', 'was', 'in', 'den', 'letzten', '25', 'Jahren', '<unk>', '</s>']
2025-05-21 14:38:52,747 - INFO - joeynmt.training - 	Source:     De volgende dia die ik laat zien  is een versnelde versie van wat er de afgelopen 25 jaar is gebeurd.
2025-05-21 14:38:52,748 - INFO - joeynmt.training - 	Reference:  Die nächste Folie, die ich Ihnen zeige, ist eine Zeitrafferaufnahme was in den letzten 25 Jahren passiert ist.
2025-05-21 14:38:52,749 - INFO - joeynmt.training - 	Hypothesis: Und die nächste <unk> die ich Ihnen zeigen  ist eine <unk> Version von dem <unk> was in den letzten 25 Jahren <unk>
2025-05-21 14:44:05,951 - INFO - joeynmt.training - Epoch  10, Step:    26600, Batch Loss:     1.340577, Batch Acc: 0.561054, Tokens per Sec:      210, Lr: 0.000210
2025-05-21 14:44:23,313 - INFO - joeynmt.training - Epoch  10: total training loss 3380.31
2025-05-21 14:44:23,315 - INFO - joeynmt.training - Training ended after  10 epochs.
2025-05-21 14:44:23,316 - INFO - joeynmt.training - Best validation result (greedy) at step    19000:   6.61 ppl.
2025-05-21 14:44:23,599 - INFO - joeynmt.model - Building an encoder-decoder model...
2025-05-21 14:44:23,779 - INFO - joeynmt.model - Enc-dec model built.
2025-05-21 14:44:26,813 - INFO - joeynmt.helpers - Load model from /mnt/c/Users/Dieb/Desktop/mt-exercise-4/models/word_level_new/19000.ckpt.
2025-05-21 14:44:26,883 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=2004),
	loss_function=None)
2025-05-21 14:44:27,270 - INFO - joeynmt.prediction - Decoding on dev set...
2025-05-21 14:44:27,277 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 14:44:27,279 - INFO - joeynmt.prediction - Predicting 1001 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 14:50:47,122 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 379.8265[sec], evaluation: 0.0000[sec]
2025-05-21 14:50:47,134 - INFO - joeynmt.prediction - Translations saved to: /mnt/c/Users/Dieb/Desktop/mt-exercise-4/models/word_level_new/00019000.hyps.dev.
2025-05-21 14:50:47,135 - INFO - joeynmt.prediction - Decoding on test set...
2025-05-21 14:50:47,137 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2025-05-21 14:50:47,138 - INFO - joeynmt.prediction - Predicting 1779 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2025-05-21 14:59:17,758 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 510.5986[sec], evaluation: 0.0000[sec]
2025-05-21 14:59:17,776 - INFO - joeynmt.prediction - Translations saved to: /mnt/c/Users/Dieb/Desktop/mt-exercise-4/models/word_level_new/00019000.hyps.test.
